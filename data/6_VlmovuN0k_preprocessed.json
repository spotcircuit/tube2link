{
  "metadata": {
    "videoId": "6_VlmovuN0k",
    "title": "OpenAI & Google Just Made Their Best Models Free",
    "channelTitle": "Matt Wolfe",
    "description": "Here's the AI news that you probably missed from this week. Learn more about Chatbase here: https://link.chatbase.co/mattwolfe\n\nDiscover More:\nüõ†Ô∏è Explore AI Tools & News: https://futuretools.io/\nüì∞ Weekly Newsletter: https://futuretools.io/newsletter\nüéôÔ∏è The Next Wave Podcast: https://youtube.com/@TheNextWavePod\n\nSocials:\nüñºÔ∏è Instagram: https://instagram.com/mr.eflow\n‚ùå Twiter/X: https://x.com/mreflow\nüßµ Threads: https://www.threads.net/@mr.eflow\nüü¶ LinkedIn: https://www.linkedin.com/in/matt-wolfe-30841712/\n\nResources From Today's Video:\nO3-Mini Launch: https://openai.com/index/openai-o3-mini\nSearch Integration: https://x.com/OpenAI/status/1885406590821421553\nFree Search Access: https://x.com/OpenAI/status/1885456576183431517\nChain Update: https://x.com/OpenAI/status/1887616278661112259\nDeep Research: https://openai.com/index/introducing-deep-research\nEU Expansion: https://x.com/OpenAI/status/1887143439097352219\nEconomic Tasks: https://x.com/sama/status/1886220904088162729\nFuture Announcement: https://x.com/sama/status/1886221586002489634\nPublic Search: https://x.com/OpenAI/status/1887224584539414983\nMemory Increase: https://x.com/OpenAI/status/1887559196377223587\nOpen Source Statement: https://techcrunch.com/2025/01/31/sam-altman-believes-openai-has-been-on-the-wrong-side-of-history-concerning-open-source\nOpenAI AMA: https://www.reddit.com/r/OpenAI/comments/1ieonxv/ama_with_openais_sam_altman_mark_chen_kevin_weil\nGemini Updates: https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025\nDeveloper Details: https://developers.googleblog.com/en/gemini-2-family-expands\nImagen 3 Release: https://developers.googleblog.com/en/imagen-3-arrives-in-the-gemini-api\nGoogle Policy Change: https://www.cnbc.com/2025/02/04/google-removes-pledge-to-not-use-ai-for-weapons-surveillance.html\nLe Chat Launch: https://x.com/MistralAI/status/1887517520040448510\nMistral Demo: https://x.com/onetwoval/status/1887547069956845634\nClaude Security: https://arstechnica.com/ai/2025/02/anthropic-dares-you-to-jailbreak-its-new-ai-model\nLyft Integration: https://www.theverge.com/news/606866/lyft-anthropic-claude-ai-chatbot-customer-service\nAlexa Revamp: https://www.reuters.com/technology/amazon-set-release-long-delayed-alexa-generative-ai-revamp-2025-02-05\nCopilot Agent: https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens\nCursor Growth: https://x.com/swyx/status/1886983583883243710\nGrok Enhancement: https://www.testingcatalog.com/x-enhances-grok-ai-with-image-editing-leveraging-aurora-model\nPet Videos: https://x.com/pika_labs/status/1885419642128392316\nPikadditions Launch: https://x.com/pika_labs/status/1887547042622562646\nVideo Restoration: https://x.com/topazlabs/status/1887497602398073234\nOmnihuman Lab: https://omnihuman-lab.github.io\nVideoJAM Research: https://hila-chefer.github.io/videojam-paper.github.io\nDeepSeek Legislation: https://www.reddit.com/r/singularity/comments/1ifk4mj/new_bill_will_make_it_a_crime_to_download\nBeatles AI Grammy: https://techcrunch.com/2025/02/03/the-beatles-won-a-grammy-last-night-thanks-to-ai\n\nLet‚Äôs work together!\n- Brand, sponsorship & business inquiries: mattwolfe@smoothmedia.co\n\n#AINews #AITools #ArtificialIntelligence\n\nTime Stamps:\n0:00 Intro\n0:14 OpenAI o3-mini\n2:55 OpenAI Deep Research\n7:21 Other OpenAI Announcements\n9:09 Google Gemini 2.0 Models\n13:50 Google Imagen 3 Update\n14:52 Use Gemini 2.0 for Free\n15:28 Chatbase\n17:02 Google on Weapons and Surveillance\n18:12 Le Chat Free AI Bot Update\n20:41 Updates From Anthropic\n21:56 GitHub Copilot Agent Mode\n23:06 Cursor - Fastest Growing SaaS\n24:35 Grok AI Image Updates\n25:11 Pika Labs AI Video Updates\n27:26 Topaz Project Starlight\n28:22 Cool AI Video Research\n30:37 DeepSeek is a Crime\n31:00 Beatles AI Grammy\n31:18 Final Thoughts"
  },
  "videoType": "informational",
  "quick_summary": "### Summary:\nThe video content covers a wide range of updates and advancements in the field of AI, focusing on recent developments from companies like OpenAI and Google. It discusses the release of new models such as OpenAI's 03 mini and Google's Gemini 2.0, highlighting their capabilities and performance in various benchmarks. Additionally, it delves into the concept of deep research and its potential economic value, as well as the implications of open-sourcing AI models. The video also touches on the use of AI in creative applications like image editing and video restoration, showcasing the innovative possibilities in the AI space.\n\n### Key Technical Points:\n1. Introduction of new AI models like OpenAI's 03 mini and Google's Gemini 2.0, with a focus on their performance in benchmarks and cost-effectiveness for developers.\n2. Discussion on the concept of deep research and its economic value, along with considerations around open-sourcing AI models.\n3. Updates on AI applications in creative fields, such as image editing and video restoration, showcasing the advancements in AI technology for creative tasks.\n4. Mention of AI tools like chatbots and image generators, highlighting their functionalities and accessibility for users across different platforms.\n5. Insights into the growth and impact of AI companies like OpenAI and Google, along with discussions on AI research papers and their implications for future developments.\n\n### Main Actions/Steps:\n1. Explore the latest AI models like OpenAI's 03 mini and Google's Gemini 2.0 to understand their performance and cost-efficiency for development projects.\n2. Stay updated on advancements in AI research and applications, including the potential economic value of deep research and the implications of open-sourcing AI models.\n3. Experiment with AI tools for creative tasks, such as image editing and video restoration, to leverage AI technology for innovative projects.\n4. Engage with AI applications like chatbots and image generators to experience their functionalities and potential for various use cases.\n5. Follow the progress and growth of AI companies like OpenAI and Google, while keeping an eye on emerging trends and research in the AI field for future insights.\n\n### Target Audience:\nThe target audience for this video content includes AI enthusiasts, developers, researchers, and individuals interested in staying updated on the latest advancements in artificial intelligence. It caters to those looking to explore new AI models, understand their performance metrics, and delve into the implications of AI research and open-sourcing strategies. Additionally, individuals interested in creative applications of AI, such",
  "patterns": {
    "steps": [
      {
        "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
        "context_before": "I'm sure I butchered at least one of those names all joined in on this Reddit AMA a few comments they made they are still planning on doing a 40 image generator so an image generator that's different than DOI",
        "context_after": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
        "position": 25
      },
      {
        "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
        "context_before": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
        "context_after": "so Gemini holds three out of the top five spots right now and the new model from open AI 03 mini Falls all the way down here at 1 2 3 4 5 6 7 8 9 10 the other place I like to look at models is this site open router which I actually learned about from Logan Kilpatrick when he was on our podcast the other day and this is actually looking at Which models are actually getting the most use",
        "position": 27
      },
      {
        "content": "so this isn't based on voting this is just based on what is actually getting used right now it's somehow watching the apis and going okay these models are what most people are using and on the day of this recording which is Thursday February 6th Claude Sonet holds the top two spots for the all category section but then Google's Gemini models hold the third and fourth spots so when it comes to usage right now Claude and Gemini are being used more than open AI apis at least today if we look at Top This Week very similar story CLA Claude Gemini Gemini followed by open AI top this month Claude Claude Gemini Gemini",
        "context_before": "so Gemini holds three out of the top five spots right now and the new model from open AI 03 mini Falls all the way down here at 1 2 3 4 5 6 7 8 9 10 the other place I like to look at models is this site open router which I actually learned about from Logan Kilpatrick when he was on our podcast the other day and this is actually looking at Which models are actually getting the most use",
        "context_after": "and then if we look at trending to see which thing people are switching over to and starting to use more and more of recently look at this number one right here Gemini flash 2.0 this is the most trending model right now and this is all categories if we look at programming we've got CLA Claud flash if we look at technology we've got Claud followed by Flash and if we look at translation Gemini Flash the previous generation of model is number one kind of a cool resource to keep tabs on which AI models are actually getting the most use at the moment but Google had some other news this week for developers that use their API you can now use the Imagine 3 AI image generator from their API and we've looked at imagine 3 quite a bit in previous videos it is a really really solid model in fact if we jump back over to the arena here click on our leaderboard if we check out their text image leaderboard we can actually see that imagine three the model from Google is ranked the top model and these are ranked in the same way you're given two images for a prompt you pick which one you like best it doesn't tell you which model you picked until after you picked it and that's how this stuff gets ranked and imagine three is number one followed by recraft followed by idiogram and so on down the line with stable diffusion falling in last",
        "position": 29
      },
      {
        "content": "goole.com another cool resource for you you know that feeling you're trying to get help from a company and you end up stuck in this endless loop of let me transfer you to the right person or we'll get back to you at 24 to 48 hours and even when you finally do get help they still need to do manual things like check your order status or schedule a meeting with you",
        "context_before": "google.com over on the right you have the option to select from various models to use and this is totally free right now you've got Gemini 2.0 flash flashlight Pro experimental flash thinking plus all of their previous models and their open source models all available for you to play with and enter prompts here and we can see we've got over a million context window as well all totally free to use over at aist studio.",
        "context_after": "it's like watching somebody use Internet Explorer but in 2025 painfully unnecessary and that's why for this video I partnered with chat base they're revolutionizing the customer experience with AI agents that don't just chat they actually do things for you we're talking AI that can instantly book meetings through calendly create support tickets with zenes or even check realtime data from your own systems what makes this really cool is that these AI agents can be trained on your own business data they're not just giving generic responses they're providing personalized help that actually makes sense it can do things on behalf of your business for your customers things like upgrading their subscription for them adding members to a dashboard for you and checking the limits of their plan all based on your custom workflows plus they work across all your channels from your website to WhatsApp to slack so that your customers can get help wherever they are and the best part you don't need to be a coding wizard to set this up chatbase has made it super simple to set up and manage these AI agents no matter what your technical level is anybody can set these things up if you want to see how chatbase can transform your customer experience from please wait to it's done check out the link in the description trust me your customers are going to thank you for this one and thank you so much to chat base for sponsoring this video there is a little bit of Darker news to come out of Google this week",
        "position": 36
      },
      {
        "content": "so they do have a Pro Plan now available that gives even more access and reduces the limit of messages per day but even the free version is still pretty dang impressive the most impressive part about mraw is how fast it is people have been claiming they're getting a th000 tokens per second output when they ask it a question which is mind-blowingly fast in fact I came across this video from Val on X here who is an intern over at mraw and well just check this out they give it the prompt generate me a kawaii calculator in canvas and we can see that it actually generated everything in like near real time that calculator that popped up that happened in real time I didn't speed up this video they didn't speed up their video they gave it the prompt to generate the kauwaii calculator and it generated the code showed an example of it they started giving it some extra prompts like now make it nature themed and within seconds created a nature themed calculator and it's all like practically instant that's how fast it is and we can see Val here says no this video is not sped up genuinely mind-blowing and it's available to all users right now",
        "context_before": "yeah",
        "context_after": "so it's available for free just to give it my own test I'm going to make sure I have the canvas turned on and I'm going to just type generate a kawaii calculator and we'll see how fast this is I'm not going to speed this up at all this is my own test here and when I press the button I will keep on talking it it wrote All That code practically instantly and that was super fast now it created in HTML",
        "position": 46
      },
      {
        "content": "so this calculator actually works uh it's pink and yellow and it generated it in 2 seconds maybe mind-blowingly fast again totally free chat.",
        "context_before": "so let's just double check to see how it did and here's the calculator that it generated let's actually see if it works 9 + 9 = 18 18 * 2 equal 36",
        "context_after": "mall.",
        "position": 49
      },
      {
        "content": "and I threw in an image of a wolf howling at the moon let's just see what happens when we try to blend those two together and my first attempt did not work at all it kind of made my face look a little more AI generated but it didn't add the wolf Hing at the Moon let's add a dut and see what happens",
        "context_before": "so I uploaded a quick video of me talking in front of my camera here",
        "context_after": "and well this time I can definitely see it added a doughnut in let's see what it looks like so it pretty much just put the dut in the corner of the video I guess you probably need a video with a little more action going on than me just you know talking into the camera like this",
        "position": 71
      },
      {
        "content": "but that's Peak Edition something fun to go play around with but I also wanted to show off what came out of topaz labs this week a company that makes a really really good upscaler I use it to upscale images all the time I use it to upscale video footage all the time they actually just released what they call Project Starlight which is the first ever diffusion model for video restoration so it takes old lowquality videos and turns them into high resolution videos so let's take a peek at this video down here of a Muhammad Ali fight you can see on the left how sort of grainy and pixely it is and the one on the right is the more upscaled version that use this project Starlite",
        "context_before": "and well this time I can definitely see it added a doughnut in let's see what it looks like so it pretty much just put the dut in the corner of the video I guess you probably need a video with a little more action going on than me just you know talking into the camera like this",
        "context_after": "and it's pretty impressive how much higher quality",
        "position": 73
      },
      {
        "content": "so I'll link it up in the description if you want to get involved there's also some really cool research that came out this week like this omnium one which is basically a tool where where you can give it a single image and an audio file and it will combine them to make like a deep fake so check this out here's like a 10-second clip of one the first frame was the image that they uploaded and then the audio you're going to hear was the audio they uploaded and it turned it into a deep fake of that person talking give people Something to Believe In and they will move from you and me to us and here's another one with Einstein what would art be like without emotions it would be empty what would our lives be like without emotions they would be empty of values so we're at a point now where you can just have an image of a person a sound bite from that person that could even be made in 11 Labs so it could be something that they never actually said and you can combine those two and make like a deep fake with them that's omnium one",
        "context_before": "and uh you got to like and comment to get access",
        "context_after": "and then there's also this one called video Jam which is like a new way of training video models that make them so much more coherent like we can see gymnastics what it looks like from most videos on the left here",
        "position": 77
      },
      {
        "content": "and that's what I got for you today again another week with tons of news I mentioned it's not going to slow down anytime soon it didn't slow down this week I doubt it's going to slow down next week",
        "context_before": "so that's pretty cool",
        "context_after": "so if if you want to make sure you stay looped in on all of the latest AI news I make a breakdown video every single Friday where I try to cover all of the news that I think is worth talking about from the past week in the world of AI I also like to create tutorials and talk about different tools and research that are coming out in the AI world",
        "position": 83
      },
      {
        "content": "so if you have feedback for me I love to hear it put it in the comments I really really appreciate anything you guys put in the comments All actually useful feedback is really really valuable to me and finally before I go I should remind you to check out futur tools.",
        "context_before": "so if that's the kind of stuff you're into give this video a like and maybe consider subscribing to this channel that'll make sure more stuff like this shows up in your YouTube feed I've also been doing some experimenting with the channel you'll probably notice I've been testing new thumbnails Styles and new titling Styles and new video Styles and things like that",
        "context_after": "this is the site that I built where I share all the cool AI tools I come across I add tons of new tools every single day there are just so many AI tools",
        "position": 86
      },
      {
        "content": "thank you so much again for tuning in thank you for nerding out with me today thanks so much to chatbase for sponsoring this video really appreciate all of you for tuning in and I will hopefully see you in the next one bye-bye",
        "context_before": "so I made it super super easy to filter them and find the exact tool you're looking for for your needs even put a match pick on here so you can find the tools that I think are the most interesting right now I keep the AI news page up to date on a daily basis I keep it simple and basic and just a list of here's all the important AI news that's happening and if you want to get the latest news and the coolest tools mailed to you twice a week join the free newsletter I'll keep you looped in directly in your inbox and by joining the free newsletter you also get access to the AI income database which is a little database I've been building out of cool ways to make money using the various AI tools that are available again it's all free over at futur tools.",
        "context_after": "",
        "position": 89
      }
    ],
    "examples": [
      {
        "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
        "context_before": "I'm sure I butchered at least one of those names all joined in on this Reddit AMA a few comments they made they are still planning on doing a 40 image generator so an image generator that's different than DOI",
        "context_after": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
        "position": 25
      },
      {
        "content": "but now the sky is a reddish color P Labs rolled out a couple new features this week including the Pika scenes which allows you to upload an image of your pet and it will actually turn that image into an AI generated video of your pet doing something interesting they also rolled out this new feature called Peak editions this is where you can give a real life video plus an image and it will take what was in that image and add it to your video like this rabbit we see here or this person opening their laundry where an octopus climbs out here's a a video of a woman with curlers in her hair and then a lion pushes her aside with curlers in his hair so you can see here's people playing basketball here's an image of a bear it puts the Bear in with them somebody opening a door somebody doing yoga with a train behind them so you can basically give it like any video plus an image and it will figure out how to like work that image into the video It's called Peak editions and this little baby popping out of the trash can is probably my favorite scene I've seen from it",
        "context_before": "and you can see we get pretty much the same image composition back",
        "context_after": "but if we head on over to p. art we can see down in the bottom we have a few new buttons like Pika scenes and Peak addition",
        "position": 66
      },
      {
        "content": "and well this time I can definitely see it added a doughnut in let's see what it looks like so it pretty much just put the dut in the corner of the video I guess you probably need a video with a little more action going on than me just you know talking into the camera like this",
        "context_before": "and I threw in an image of a wolf howling at the moon let's just see what happens when we try to blend those two together and my first attempt did not work at all it kind of made my face look a little more AI generated but it didn't add the wolf Hing at the Moon let's add a dut and see what happens",
        "context_after": "but that's Peak Edition something fun to go play around with but I also wanted to show off what came out of topaz labs this week a company that makes a really really good upscaler I use it to upscale images all the time I use it to upscale video footage all the time they actually just released what they call Project Starlight which is the first ever diffusion model for video restoration so it takes old lowquality videos and turns them into high resolution videos so let's take a peek at this video down here of a Muhammad Ali fight you can see on the left how sort of grainy and pixely it is and the one on the right is the more upscaled version that use this project Starlite",
        "position": 72
      },
      {
        "content": "so I'll link it up in the description if you want to get involved there's also some really cool research that came out this week like this omnium one which is basically a tool where where you can give it a single image and an audio file and it will combine them to make like a deep fake so check this out here's like a 10-second clip of one the first frame was the image that they uploaded and then the audio you're going to hear was the audio they uploaded and it turned it into a deep fake of that person talking give people Something to Believe In and they will move from you and me to us and here's another one with Einstein what would art be like without emotions it would be empty what would our lives be like without emotions they would be empty of values so we're at a point now where you can just have an image of a person a sound bite from that person that could even be made in 11 Labs so it could be something that they never actually said and you can combine those two and make like a deep fake with them that's omnium one",
        "context_before": "and uh you got to like and comment to get access",
        "context_after": "and then there's also this one called video Jam which is like a new way of training video models that make them so much more coherent like we can see gymnastics what it looks like from most videos on the left here",
        "position": 77
      },
      {
        "content": "so if that's the kind of stuff you're into give this video a like and maybe consider subscribing to this channel that'll make sure more stuff like this shows up in your YouTube feed I've also been doing some experimenting with the channel you'll probably notice I've been testing new thumbnails Styles and new titling Styles and new video Styles and things like that",
        "context_before": "so if if you want to make sure you stay looped in on all of the latest AI news I make a breakdown video every single Friday where I try to cover all of the news that I think is worth talking about from the past week in the world of AI I also like to create tutorials and talk about different tools and research that are coming out in the AI world",
        "context_after": "so if you have feedback for me I love to hear it put it in the comments I really really appreciate anything you guys put in the comments All actually useful feedback is really really valuable to me and finally before I go I should remind you to check out futur tools.",
        "position": 85
      }
    ],
    "key_points": [
      {
        "content": "yes only a single digit meaning you know between 1 and 9% but that single digigit percentage still likely adds up to billions of dollars worth of value that this deep research is capable of doing and not only that but Sam te's that there's still something else coming he said note this is not the one more thing for 03 mini a few more days for that and he said that on the same day that deep research came out he was commenting that 03 mini came out and then oh here's deep research which makes all of this stuff even better and we still have one more thing to show you which is exciting but we're not telling you yet but open AI wasn't even done there with announcements this week they had a handful of smaller announcements like the fact that chat GPT search is now a available to everyone over on chat gp.com no sign up required",
        "context_before": "I have ever tried it is absolutely insane because it does the research for you using the Deep research so it will go off on the web and search out items for you as part of the research and then it uses the 01 Pros reasoning to really really think through everything that it came back with and that's how I got that insane detailed report on what I should do on my YouTube channel it wasn't only using what was in its training data it literally did the research did the Chain of Thought reasoning and then spit back out that entire report that's what makes it so powerful is when you start combining all of these things they all combine for an insanely powerful experience where the output is just mindblowing and even if you're in the EU you also get access to deep research deep research is now rolled out to 100% of All Pro users including in the UK EU Norway Iceland lonstein and Switzerland and one interesting thing that Sam Alman said not long after this came out my very approximate Vibe is that it can do a single digit percentage of all economically valuable tasks in the world which is a wild Milestone",
        "context_after": "so if you don't want to use Google search anymore you'd rather use chat GPT for your search you can just go to chat gp.com and do web searches that are combined with AI now without even logging in so now it's like an actual true competitor to what perplexity is doing they also increase the memory limit in chat GPT for plus pro and team users by 25%",
        "position": 20
      },
      {
        "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
        "context_before": "I'm sure I butchered at least one of those names all joined in on this Reddit AMA a few comments they made they are still planning on doing a 40 image generator so an image generator that's different than DOI",
        "context_after": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
        "position": 25
      },
      {
        "content": "so I made it super super easy to filter them and find the exact tool you're looking for for your needs even put a match pick on here so you can find the tools that I think are the most interesting right now I keep the AI news page up to date on a daily basis I keep it simple and basic and just a list of here's all the important AI news that's happening and if you want to get the latest news and the coolest tools mailed to you twice a week join the free newsletter I'll keep you looped in directly in your inbox and by joining the free newsletter you also get access to the AI income database which is a little database I've been building out of cool ways to make money using the various AI tools that are available again it's all free over at futur tools.",
        "context_before": "this is the site that I built where I share all the cool AI tools I come across I add tons of new tools every single day there are just so many AI tools",
        "context_after": "thank you so much again for tuning in thank you for nerding out with me today thanks so much to chatbase for sponsoring this video really appreciate all of you for tuning in and I will hopefully see you in the next one bye-bye",
        "position": 88
      }
    ],
    "lists": [],
    "code_blocks": []
  },
  "semantic": {
    "actions": [
      {
        "content": "and I don't want to waste your time",
        "importance": 0.1132713183760643
      },
      {
        "content": "so let's get into this week's AI news breakdown starting with news that actually came out last week",
        "importance": 0.2361585795879364
      },
      {
        "content": "but I record these videos on Thursdays and this news came out on Friday of last week it was when open AI released their 03 mini now we did talk about it in last Friday's video because we knew it was going to come out on Friday but now that we actually have access to it I figured let's talk about it real quick this new 03 model outperforms pretty much every other model out there in math except for 01 Pro which is not actually listed on this chart in PhD level science questions the 03 mini High version beats everything else that's out there except for of course 01",
        "importance": 0.25234946608543396
      },
      {
        "content": "but I do worry that summarized Chain of Thought is actually worse than nothing at all true Chain of Thought exposure acts as a prompt debugger it helps us steer the model summarized Chain of Thought up escapes this and potentially adds errors and it makes it harder to debug so if you're looking at something like deep seek R1 and you can see literally everything it's thinking and it gives you an incorrect answer you could literally go back and look through the chain of thought and figure out where it's screwed up these summarized chains of thought that open ai3 is giving us you can't really do that",
        "importance": 0.18715636432170868
      },
      {
        "content": "but in my opinion the even bigger news that came out from open AI this week wasn't even the fact that they gave us 03 mini on Friday it was that over the weekend they gave us deep research unfortunately deep research is only available to Pro users on the $200 a month plan which I do know makes it economically infeasible for a lot of people",
        "importance": 0.27992498874664307
      },
      {
        "content": "it is kind of interesting that they named it deep research because Google has a product called Gemini with deep research it's exactly the same naming scheme which is definitely going to confuse people but it does work really",
        "importance": 0.19970372319221497
      },
      {
        "content": "well I asked deep research to help me with a YouTube strategy it actually gave me some follow-up questions so that it can better understand what I was trying to accomplish like my current strategy on long form versus short form videos my current video length and format how I decide on tutorials like what my competitors are doing what my monetization focuses are things like that I answered its questions",
        "importance": 0.18506883084774017
      },
      {
        "content": "and then it gave me just an absolute Beast of a write up of how I should manage my YouTube channel and it is really really really indepth and honestly created an amazing killer strategy like I'm literally following through on this strategy with my YouTube channel now it wrote up this giant essay here",
        "importance": 0.17712484300136566
      },
      {
        "content": "and I actually pasted it back into chat GPT this is the entire write up that it gave me I pasted it back into GPT 40 and asked it to give me a stepbystep checklist and you can see here that it simplified everything and gave me a checklist of what to do for my Channel even gave me a 4-week breakdown to dial it all in so deep research has been a game Cher for me",
        "importance": 0.2014639675617218
      },
      {
        "content": "I know it's on the $200 a month plan but had I hired like a YouTube consultant to look at my channel analyze everything I was doing and give me a detailed like 10 page Report with a step-by-step checklist of what I need to do on the channel they would have charged me way more than $200 so I feel like I got the value out of that from that alone",
        "importance": 0.17745819687843323
      },
      {
        "content": "but I also don't want you to feel like I'm trying to sell you on getting the $200 month plan for most people it's probably still not worth it",
        "importance": 0.09457724541425705
      },
      {
        "content": "I've just personally found a lot of value from it there's a recent benchmark test that came out titled Humanity's last exam and you can see how some of the other existing models performed on this benchmark test GPT 40 got a 3.3% in accuracy open eyes 01 got a 9.1 deep seek R1 got a 9.4 the new openai 03 mini High got a 13.0 open AI with deep research got a 26 .6% on the accuracy if you have a pro account if you combind 01 Pro with deep research it is hands down the most powerful AI large language model",
        "importance": 0.22015787661075592
      },
      {
        "content": "I have ever tried it is absolutely insane because it does the research for you using the Deep research so it will go off on the web and search out items for you as part of the research and then it uses the 01 Pros reasoning to really really think through everything that it came back with and that's how I got that insane detailed report on what I should do on my YouTube channel it wasn't only using what was in its training data it literally did the research did the Chain of Thought reasoning and then spit back out that entire report that's what makes it so powerful is when you start combining all of these things they all combine for an insanely powerful experience where the output is just mindblowing and even if you're in the EU you also get access to deep research deep research is now rolled out to 100% of All Pro users including in the UK EU Norway Iceland lonstein and Switzerland and one interesting thing that Sam Alman said not long after this came out my very approximate Vibe is that it can do a single digit percentage of all economically valuable tasks in the world which is a wild Milestone",
        "importance": 0.2344619780778885
      },
      {
        "content": "yes only a single digit meaning you know between 1 and 9% but that single digigit percentage still likely adds up to billions of dollars worth of value that this deep research is capable of doing and not only that but Sam te's that there's still something else coming he said note this is not the one more thing for 03 mini a few more days for that and he said that on the same day that deep research came out he was commenting that 03 mini came out and then oh here's deep research which makes all of this stuff even better and we still have one more thing to show you which is exciting but we're not telling you yet but open AI wasn't even done there with announcements this week they had a handful of smaller announcements like the fact that chat GPT search is now a available to everyone over on chat gp.com no sign up required",
        "importance": 0.2840880751609802
      },
      {
        "content": "so if you don't want to use Google search anymore you'd rather use chat GPT for your search you can just go to chat gp.com and do web searches that are combined with AI now without even logging in so now it's like an actual true competitor to what perplexity is doing they also increase the memory limit in chat GPT for plus pro and team users by 25%",
        "importance": 0.24139338731765747
      },
      {
        "content": "yeah it's been a big week for open Ai and since open AI had so much going on this week they actually took to Reddit to do an AMA where Sam Alman Mark Chen Kevin wheel serenos nanian Michelle Pocas and hungu ren",
        "importance": 0.23442082107067108
      },
      {
        "content": "I'm sure I butchered at least one of those names all joined in on this Reddit AMA a few comments they made they are still planning on doing a 40 image generator so an image generator that's different than DOI",
        "importance": 0.1813376098871231
      },
      {
        "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
        "importance": 0.2657625079154968
      },
      {
        "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
        "importance": 0.18657425045967102
      },
      {
        "content": "so Gemini holds three out of the top five spots right now and the new model from open AI 03 mini Falls all the way down here at 1 2 3 4 5 6 7 8 9 10 the other place I like to look at models is this site open router which I actually learned about from Logan Kilpatrick when he was on our podcast the other day and this is actually looking at Which models are actually getting the most use",
        "importance": 0.17645390331745148
      },
      {
        "content": "so this isn't based on voting this is just based on what is actually getting used right now it's somehow watching the apis and going okay these models are what most people are using and on the day of this recording which is Thursday February 6th Claude Sonet holds the top two spots for the all category section but then Google's Gemini models hold the third and fourth spots so when it comes to usage right now Claude and Gemini are being used more than open AI apis at least today if we look at Top This Week very similar story CLA Claude Gemini Gemini followed by open AI top this month Claude Claude Gemini Gemini",
        "importance": 0.26780012249946594
      },
      {
        "content": "and then if we look at trending to see which thing people are switching over to and starting to use more and more of recently look at this number one right here Gemini flash 2.0 this is the most trending model right now and this is all categories if we look at programming we've got CLA Claud flash if we look at technology we've got Claud followed by Flash and if we look at translation Gemini Flash the previous generation of model is number one kind of a cool resource to keep tabs on which AI models are actually getting the most use at the moment but Google had some other news this week for developers that use their API you can now use the Imagine 3 AI image generator from their API and we've looked at imagine 3 quite a bit in previous videos it is a really really solid model in fact if we jump back over to the arena here click on our leaderboard if we check out their text image leaderboard we can actually see that imagine three the model from Google is ranked the top model and these are ranked in the same way you're given two images for a prompt you pick which one you like best it doesn't tell you which model you picked until after you picked it and that's how this stuff gets ranked and imagine three is number one followed by recraft followed by idiogram and so on down the line with stable diffusion falling in last",
        "importance": 0.2901161313056946
      },
      {
        "content": "but if you're a developer and you want to use this model within your workflow you now have access to it if you're not a developer and you want to play with imagine 3 the best way to do it is over in Google Labs over at labs.",
        "importance": 0.17067064344882965
      },
      {
        "content": "google.com over on the right you have the option to select from various models to use and this is totally free right now you've got Gemini 2.0 flash flashlight Pro experimental flash thinking plus all of their previous models and their open source models all available for you to play with and enter prompts here and we can see we've got over a million context window as well all totally free to use over at aist studio.",
        "importance": 0.2063865065574646
      },
      {
        "content": "goole.com another cool resource for you you know that feeling you're trying to get help from a company and you end up stuck in this endless loop of let me transfer you to the right person or we'll get back to you at 24 to 48 hours and even when you finally do get help they still need to do manual things like check your order status or schedule a meeting with you",
        "importance": 0.11206184327602386
      },
      {
        "content": "it's like watching somebody use Internet Explorer but in 2025 painfully unnecessary and that's why for this video I partnered with chat base they're revolutionizing the customer experience with AI agents that don't just chat they actually do things for you we're talking AI that can instantly book meetings through calendly create support tickets with zenes or even check realtime data from your own systems what makes this really cool is that these AI agents can be trained on your own business data they're not just giving generic responses they're providing personalized help that actually makes sense it can do things on behalf of your business for your customers things like upgrading their subscription for them adding members to a dashboard for you and checking the limits of their plan all based on your custom workflows plus they work across all your channels from your website to WhatsApp to slack so that your customers can get help wherever they are and the best part you don't need to be a coding wizard to set this up chatbase has made it super simple to set up and manage these AI agents no matter what your technical level is anybody can set these things up if you want to see how chatbase can transform your customer experience from please wait to it's done check out the link in the description trust me your customers are going to thank you for this one and thank you so much to chat base for sponsoring this video there is a little bit of Darker news to come out of Google this week",
        "importance": 0.24828585982322693
      },
      {
        "content": "m.ai and it can do a lot of the same things you would get out of chat GPT things like search the web generate images code interpreter and it even has a canvas mode where it'll put any sort of code and writing inside of a canvas very similar to chat GPT they do now have a Pro Plan which I believe is 15 bucks a month",
        "importance": 0.2764517664909363
      },
      {
        "content": "so they do have a Pro Plan now available that gives even more access and reduces the limit of messages per day but even the free version is still pretty dang impressive the most impressive part about mraw is how fast it is people have been claiming they're getting a th000 tokens per second output when they ask it a question which is mind-blowingly fast in fact I came across this video from Val on X here who is an intern over at mraw and well just check this out they give it the prompt generate me a kawaii calculator in canvas and we can see that it actually generated everything in like near real time that calculator that popped up that happened in real time I didn't speed up this video they didn't speed up their video they gave it the prompt to generate the kauwaii calculator and it generated the code showed an example of it they started giving it some extra prompts like now make it nature themed and within seconds created a nature themed calculator and it's all like practically instant that's how fast it is and we can see Val here says no this video is not sped up genuinely mind-blowing and it's available to all users right now",
        "importance": 0.27121978998184204
      },
      {
        "content": "so it's available for free just to give it my own test I'm going to make sure I have the canvas turned on and I'm going to just type generate a kawaii calculator and we'll see how fast this is I'm not going to speed this up at all this is my own test here and when I press the button I will keep on talking it it wrote All That code practically instantly and that was super fast now it created in HTML",
        "importance": 0.1921951323747635
      },
      {
        "content": "so let's just double check to see how it did and here's the calculator that it generated let's actually see if it works 9 + 9 = 18 18 * 2 equal 36",
        "importance": 0.07883941382169724
      },
      {
        "content": "there was a little bit of news out of anthropic this week they gave us an area to try to jailbreak clad and see if we can get it to Output dangerous responses there's eight levels that it goes through and they actually have a bounty where they'll actually pay you if you manage to jailbreak all eight questions so far nobody's managed to do it but there is a little bit of other news around anthropic Lyft is starting to use anthropic clad for their customer service claiming that it reduces the average resolution time for a request by 87%",
        "importance": 0.13830210268497467
      },
      {
        "content": "so if you're using Lyft and you run into issues",
        "importance": 0.08756550401449203
      },
      {
        "content": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat",
        "importance": 0.168312668800354
      },
      {
        "content": "I've personally never used GitHub co-pilot I've been much more on the cursor train myself",
        "importance": 0.19514645636081696
      },
      {
        "content": "but this sounds really really handy for it to sort of double check its own work and pull stuff in from the terminal when something's not working properly that just sounds like great quality of life updates that I imagine tools like cursor will get as well and since we mentioned cursor I want to point this out real quick cuz I found it fascinating that cursor is literally the fastest growing SAS company in the history of SAS",
        "importance": 0.17942434549331665
      },
      {
        "content": "so SAS is software as a service and if we look at this chart here we can see this is cursor's growth curve it basically took one year to get to 100 million in annual recurring Revenue we can wise deal together AI Core weave open Ai and DocuSign and all of their respective charts it took docine 10 years to get to 100 million in annual recurring Revenue it took cursor only one year that's pretty mind-blowing how quickly cursor is growing",
        "importance": 0.21908412873744965
      },
      {
        "content": "and I think it comes down to the fact that tools like cursor make it so literally anybody on the planet can write little software for themselves I've used it multiple times to solve little problems in my own workflows like I wanted a tool to quickly convert files from any image format into a JPEG I use cursor to create that app in about 15 minutes",
        "importance": 0.1667919158935547
      },
      {
        "content": "and now I have a simple workflow where whenever I grab an image from any app or download on the Internet or anything I don't have to open it up in like a photos app",
        "importance": 0.09081941097974777
      },
      {
        "content": "and I don't really know how to code",
        "importance": 0.12127552181482315
      },
      {
        "content": "but now the sky is a reddish color P Labs rolled out a couple new features this week including the Pika scenes which allows you to upload an image of your pet and it will actually turn that image into an AI generated video of your pet doing something interesting they also rolled out this new feature called Peak editions this is where you can give a real life video plus an image and it will take what was in that image and add it to your video like this rabbit we see here or this person opening their laundry where an octopus climbs out here's a a video of a woman with curlers in her hair and then a lion pushes her aside with curlers in his hair so you can see here's people playing basketball here's an image of a bear it puts the Bear in with them somebody opening a door somebody doing yoga with a train behind them so you can basically give it like any video plus an image and it will figure out how to like work that image into the video It's called Peak editions and this little baby popping out of the trash can is probably my favorite scene I've seen from it",
        "importance": 0.21098895370960236
      },
      {
        "content": "but if we head on over to p. art we can see down in the bottom we have a few new buttons like Pika scenes and Peak addition",
        "importance": 0.20980238914489746
      },
      {
        "content": "so if we do Pika scenes I can throw in a picture of my dog here give it a prompt like the pet is flying on a private jet and here's the video we got out of it with my dog flying on a private plane actually looks pretty good kind of looks like him other than the fact that like his back legs don't move properly when he's walking around uh it actually got the face and head looking pretty accurate honestly",
        "importance": 0.1263890564441681
      },
      {
        "content": "and well this time I can definitely see it added a doughnut in let's see what it looks like so it pretty much just put the dut in the corner of the video I guess you probably need a video with a little more action going on than me just you know talking into the camera like this",
        "importance": 0.16110770404338837
      },
      {
        "content": "but that's Peak Edition something fun to go play around with but I also wanted to show off what came out of topaz labs this week a company that makes a really really good upscaler I use it to upscale images all the time I use it to upscale video footage all the time they actually just released what they call Project Starlight which is the first ever diffusion model for video restoration so it takes old lowquality videos and turns them into high resolution videos so let's take a peek at this video down here of a Muhammad Ali fight you can see on the left how sort of grainy and pixely it is and the one on the right is the more upscaled version that use this project Starlite",
        "importance": 0.17752788960933685
      },
      {
        "content": "so I'll link it up in the description if you want to get involved there's also some really cool research that came out this week like this omnium one which is basically a tool where where you can give it a single image and an audio file and it will combine them to make like a deep fake so check this out here's like a 10-second clip of one the first frame was the image that they uploaded and then the audio you're going to hear was the audio they uploaded and it turned it into a deep fake of that person talking give people Something to Believe In and they will move from you and me to us and here's another one with Einstein what would art be like without emotions it would be empty what would our lives be like without emotions they would be empty of values so we're at a point now where you can just have an image of a person a sound bite from that person that could even be made in 11 Labs so it could be something that they never actually said and you can combine those two and make like a deep fake with them that's omnium one",
        "importance": 0.18070411682128906
      },
      {
        "content": "and then if we look at it again with the person on the right it actually looks like somebody doing gymnastics it figured out the proper physics and how people should move here's another one of somebody doing like a weird ring thing where that doesn't look right but if we go back and look at the updated version on the right you can see it actually figured out how to make it look and this is just again a new way of training these AI video models so they have a much better understanding of the physics and how they should look you're going to see this in a lot of other video models you'll probably see this in cling and Runway and hellu Ai and Pika and all these other tools because with this research they can actually sort of attach this to their existing technology now I'm not going to go too deep into these research papers cuz I actually did a video earlier this week called seven insane AI video breakthroughs you must see I talk about those two papers that I just showed you as well as five other papers that I find really fascinating that have come out within the last couple weeks",
        "importance": 0.2695239186286926
      },
      {
        "content": "so check that out if you want to dive deeper into all of this cool AI research that's coming out that maybe we don't have access to but it's like within weeks maybe months away of it being publicly available for anybody to get their hands on and a couple last real quick things there's a new bill introduced I believe in the Senate that wants to make it illegal to download deep seek with a penalty of up to 20 years in prison now I don't think this thing's everever going to get passed but there are people in the government that want to make it illegal to use some of these open source models it's something to be aware of and in the final bit of news that I'll share this week the Beatles won a Grammy this week for a song that was assisted with AI",
        "importance": 0.26410508155822754
      },
      {
        "content": "and that's what I got for you today again another week with tons of news I mentioned it's not going to slow down anytime soon it didn't slow down this week I doubt it's going to slow down next week",
        "importance": 0.15438756346702576
      },
      {
        "content": "so if if you want to make sure you stay looped in on all of the latest AI news I make a breakdown video every single Friday where I try to cover all of the news that I think is worth talking about from the past week in the world of AI I also like to create tutorials and talk about different tools and research that are coming out in the AI world",
        "importance": 0.2542753517627716
      },
      {
        "content": "so if that's the kind of stuff you're into give this video a like and maybe consider subscribing to this channel that'll make sure more stuff like this shows up in your YouTube feed I've also been doing some experimenting with the channel you'll probably notice I've been testing new thumbnails Styles and new titling Styles and new video Styles and things like that",
        "importance": 0.17693102359771729
      },
      {
        "content": "so if you have feedback for me I love to hear it put it in the comments I really really appreciate anything you guys put in the comments All actually useful feedback is really really valuable to me and finally before I go I should remind you to check out futur tools.",
        "importance": 0.19497254490852356
      }
    ],
    "problems": [
      {
        "problem": "so if you're using Lyft and you run into issues",
        "solution": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat"
      },
      {
        "problem": "and you try to contact customer support it's actually using Claud to sort of help you get through whatever issue you've got we also learned that Amazon Alexa has an event coming up on February 26 Amazon's holding an event and a spokesperson said the event is Alexa focused but then declined to elaborate",
        "solution": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat"
      }
    ],
    "comparisons": [
      {
        "content": "open AI said updated Chain of Thought in open aai 03 mini for free and paid users and in 03 mini High for paid users now the Chain of Thought that it's showing here isn't actually the true Chain of Thought that's happening it's not like what you see in deep seek R1 where you see literally everything the model's thinking before it gives you the response this gives you sort of like a summarized version of what it's thinking before it gives you a response McKay Wrigley here even argues that it's actually worse than giving us nothing at all he says 03 mini is exceptionally great",
        "context": "and I guess when it was originally released for free members it didn't actually show The Chain of Thought but as of February 6th even that's been updated for both free and paid users"
      },
      {
        "content": "but I do worry that summarized Chain of Thought is actually worse than nothing at all true Chain of Thought exposure acts as a prompt debugger it helps us steer the model summarized Chain of Thought up escapes this and potentially adds errors and it makes it harder to debug so if you're looking at something like deep seek R1 and you can see literally everything it's thinking and it gives you an incorrect answer you could literally go back and look through the chain of thought and figure out where it's screwed up these summarized chains of thought that open ai3 is giving us you can't really do that",
        "context": "open AI said updated Chain of Thought in open aai 03 mini for free and paid users and in 03 mini High for paid users now the Chain of Thought that it's showing here isn't actually the true Chain of Thought that's happening it's not like what you see in deep seek R1 where you see literally everything the model's thinking before it gives you the response this gives you sort of like a summarized version of what it's thinking before it gives you a response McKay Wrigley here even argues that it's actually worse than giving us nothing at all he says 03 mini is exceptionally great"
      },
      {
        "content": "well I asked deep research to help me with a YouTube strategy it actually gave me some follow-up questions so that it can better understand what I was trying to accomplish like my current strategy on long form versus short form videos my current video length and format how I decide on tutorials like what my competitors are doing what my monetization focuses are things like that I answered its questions",
        "context": "it is kind of interesting that they named it deep research because Google has a product called Gemini with deep research it's exactly the same naming scheme which is definitely going to confuse people but it does work really"
      },
      {
        "content": "yes only a single digit meaning you know between 1 and 9% but that single digigit percentage still likely adds up to billions of dollars worth of value that this deep research is capable of doing and not only that but Sam te's that there's still something else coming he said note this is not the one more thing for 03 mini a few more days for that and he said that on the same day that deep research came out he was commenting that 03 mini came out and then oh here's deep research which makes all of this stuff even better and we still have one more thing to show you which is exciting but we're not telling you yet but open AI wasn't even done there with announcements this week they had a handful of smaller announcements like the fact that chat GPT search is now a available to everyone over on chat gp.com no sign up required",
        "context": "I have ever tried it is absolutely insane because it does the research for you using the Deep research so it will go off on the web and search out items for you as part of the research and then it uses the 01 Pros reasoning to really really think through everything that it came back with and that's how I got that insane detailed report on what I should do on my YouTube channel it wasn't only using what was in its training data it literally did the research did the Chain of Thought reasoning and then spit back out that entire report that's what makes it so powerful is when you start combining all of these things they all combine for an insanely powerful experience where the output is just mindblowing and even if you're in the EU you also get access to deep research deep research is now rolled out to 100% of All Pro users including in the UK EU Norway Iceland lonstein and Switzerland and one interesting thing that Sam Alman said not long after this came out my very approximate Vibe is that it can do a single digit percentage of all economically valuable tasks in the world which is a wild Milestone"
      },
      {
        "content": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
        "context": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs"
      },
      {
        "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
        "context": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break"
      },
      {
        "content": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat",
        "context": "so really all we know is that they have an event coming up they're going to be talking about Alexa and most people believe that they're going to roll out Alexa with a much smarter AI Amazon said in the past that their AI in Alexa is going to be powered by anthropics Claud"
      },
      {
        "content": "it is here's another example where we can see the side by side of what looks like was recorded on a VHS tape to something that looks quite a bit better quality here it looks like it's an early access right now",
        "context": "and it's pretty impressive how much higher quality"
      },
      {
        "content": "and then if we look at it again with the person on the right it actually looks like somebody doing gymnastics it figured out the proper physics and how people should move here's another one of somebody doing like a weird ring thing where that doesn't look right but if we go back and look at the updated version on the right you can see it actually figured out how to make it look and this is just again a new way of training these AI video models so they have a much better understanding of the physics and how they should look you're going to see this in a lot of other video models you'll probably see this in cling and Runway and hellu Ai and Pika and all these other tools because with this research they can actually sort of attach this to their existing technology now I'm not going to go too deep into these research papers cuz I actually did a video earlier this week called seven insane AI video breakthroughs you must see I talk about those two papers that I just showed you as well as five other papers that I find really fascinating that have come out within the last couple weeks",
        "context": "and then there's also this one called video Jam which is like a new way of training video models that make them so much more coherent like we can see gymnastics what it looks like from most videos on the left here"
      }
    ]
  },
  "roles": {
    "user": [
      {
        "content": "but I record these videos on Thursdays and this news came out on Friday of last week it was when open AI released their 03 mini now we did talk about it in last Friday's video because we knew it was going to come out on Friday but now that we actually have access to it I figured let's talk about it real quick this new 03 model outperforms pretty much every other model out there in math except for 01 Pro which is not actually listed on this chart in PhD level science questions the 03 mini High version beats everything else that's out there except for of course 01",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "Pro it's good at coding good at software engineering and it's pretty much the most powerful model on the market other than 01 Pro which is only in the $200 a month tier this new 03 mini however is available in every tier and available in the API as well Pro users will have unlimited access to 03 mini and plus and team users will have triple the rate limits versus 01 mini free users can try 03 mini in chat GPT by selecting the reason button under the message composer so even free chat GPT users are getting access to this newest state-of-the-art model from open AI you can even combine this 03 Mini model with their search model even on free plans open AI said try search plus reasoning together in chat GPT free users can use open aai 03 min with search by selecting the search plus reason buttons together",
        "matched_patterns": [
          "select",
          "open"
        ]
      },
      {
        "content": "so if you're on the free plan and you want to use the new 03 model you'd select the reason button if you want to combine it with search you select both search and reason",
        "matched_patterns": [
          "select"
        ]
      },
      {
        "content": "open AI said updated Chain of Thought in open aai 03 mini for free and paid users and in 03 mini High for paid users now the Chain of Thought that it's showing here isn't actually the true Chain of Thought that's happening it's not like what you see in deep seek R1 where you see literally everything the model's thinking before it gives you the response this gives you sort of like a summarized version of what it's thinking before it gives you a response McKay Wrigley here even argues that it's actually worse than giving us nothing at all he says 03 mini is exceptionally great",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "but I do worry that summarized Chain of Thought is actually worse than nothing at all true Chain of Thought exposure acts as a prompt debugger it helps us steer the model summarized Chain of Thought up escapes this and potentially adds errors and it makes it harder to debug so if you're looking at something like deep seek R1 and you can see literally everything it's thinking and it gives you an incorrect answer you could literally go back and look through the chain of thought and figure out where it's screwed up these summarized chains of thought that open ai3 is giving us you can't really do that",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "but in my opinion the even bigger news that came out from open AI this week wasn't even the fact that they gave us 03 mini on Friday it was that over the weekend they gave us deep research unfortunately deep research is only available to Pro users on the $200 a month plan which I do know makes it economically infeasible for a lot of people",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "I've just personally found a lot of value from it there's a recent benchmark test that came out titled Humanity's last exam and you can see how some of the other existing models performed on this benchmark test GPT 40 got a 3.3% in accuracy open eyes 01 got a 9.1 deep seek R1 got a 9.4 the new openai 03 mini High got a 13.0 open AI with deep research got a 26 .6% on the accuracy if you have a pro account if you combind 01 Pro with deep research it is hands down the most powerful AI large language model",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "yes only a single digit meaning you know between 1 and 9% but that single digigit percentage still likely adds up to billions of dollars worth of value that this deep research is capable of doing and not only that but Sam te's that there's still something else coming he said note this is not the one more thing for 03 mini a few more days for that and he said that on the same day that deep research came out he was commenting that 03 mini came out and then oh here's deep research which makes all of this stuff even better and we still have one more thing to show you which is exciting but we're not telling you yet but open AI wasn't even done there with announcements this week they had a handful of smaller announcements like the fact that chat GPT search is now a available to everyone over on chat gp.com no sign up required",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "so if you don't want to use Google search anymore you'd rather use chat GPT for your search you can just go to chat gp.com and do web searches that are combined with AI now without even logging in so now it's like an actual true competitor to what perplexity is doing they also increase the memory limit in chat GPT for plus pro and team users by 25%",
        "matched_patterns": [
          "go to"
        ]
      },
      {
        "content": "yeah it's been a big week for open Ai and since open AI had so much going on this week they actually took to Reddit to do an AMA where Sam Alman Mark Chen Kevin wheel serenos nanian Michelle Pocas and hungu ren",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
        "matched_patterns": [
          "enter",
          "input"
        ]
      },
      {
        "content": "so Gemini holds three out of the top five spots right now and the new model from open AI 03 mini Falls all the way down here at 1 2 3 4 5 6 7 8 9 10 the other place I like to look at models is this site open router which I actually learned about from Logan Kilpatrick when he was on our podcast the other day and this is actually looking at Which models are actually getting the most use",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "so this isn't based on voting this is just based on what is actually getting used right now it's somehow watching the apis and going okay these models are what most people are using and on the day of this recording which is Thursday February 6th Claude Sonet holds the top two spots for the all category section but then Google's Gemini models hold the third and fourth spots so when it comes to usage right now Claude and Gemini are being used more than open AI apis at least today if we look at Top This Week very similar story CLA Claude Gemini Gemini followed by open AI top this month Claude Claude Gemini Gemini",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "and then if we look at trending to see which thing people are switching over to and starting to use more and more of recently look at this number one right here Gemini flash 2.0 this is the most trending model right now and this is all categories if we look at programming we've got CLA Claud flash if we look at technology we've got Claud followed by Flash and if we look at translation Gemini Flash the previous generation of model is number one kind of a cool resource to keep tabs on which AI models are actually getting the most use at the moment but Google had some other news this week for developers that use their API you can now use the Imagine 3 AI image generator from their API and we've looked at imagine 3 quite a bit in previous videos it is a really really solid model in fact if we jump back over to the arena here click on our leaderboard if we check out their text image leaderboard we can actually see that imagine three the model from Google is ranked the top model and these are ranked in the same way you're given two images for a prompt you pick which one you like best it doesn't tell you which model you picked until after you picked it and that's how this stuff gets ranked and imagine three is number one followed by recraft followed by idiogram and so on down the line with stable diffusion falling in last",
        "matched_patterns": [
          "click"
        ]
      },
      {
        "content": "google.com over on the right you have the option to select from various models to use and this is totally free right now you've got Gemini 2.0 flash flashlight Pro experimental flash thinking plus all of their previous models and their open source models all available for you to play with and enter prompts here and we can see we've got over a million context window as well all totally free to use over at aist studio.",
        "matched_patterns": [
          "select",
          "open",
          "enter"
        ]
      },
      {
        "content": "and it seems like Demis has sort of changed his thinking on it all right so open a",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "so now I'm going to sort of Rapid Fire a whole bunch of other little things that happen in the world of AI starting with the fact that Mr all AI a sort of competitor to open AI out of France launched a new version of lechette now they've had lechette for a while it's a free chatbot that you can find over at chat.",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "so it's available for free just to give it my own test I'm going to make sure I have the canvas turned on and I'm going to just type generate a kawaii calculator and we'll see how fast this is I'm not going to speed this up at all this is my own test here and when I press the button I will keep on talking it it wrote All That code practically instantly and that was super fast now it created in HTML",
        "matched_patterns": [
          "type"
        ]
      },
      {
        "content": "so SAS is software as a service and if we look at this chart here we can see this is cursor's growth curve it basically took one year to get to 100 million in annual recurring Revenue we can wise deal together AI Core weave open Ai and DocuSign and all of their respective charts it took docine 10 years to get to 100 million in annual recurring Revenue it took cursor only one year that's pretty mind-blowing how quickly cursor is growing",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "and now I have a simple workflow where whenever I grab an image from any app or download on the Internet or anything I don't have to open it up in like a photos app",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "and save it as a new file I literally just drag and drop it over a box it converts it for me automatically it saves me so much time",
        "matched_patterns": [
          "save"
        ]
      },
      {
        "content": "so I see why it's growing so quickly it totally democratized the ability to make simple apps all right let's move on to the sort of creative side of AI cuz there's been a handful of updates in that world as well including the fact that if you use grock inside of X you can now actually edit images if I head over to grock inside of X here and tell it to generate an image of a wolf howling at the moon we get four Images here now if I click on one of these images there's a new button that says edit with Gro I can click on this button and Des describe what I want to change in the image I'll say make the sky a red color we'll give it that prompt",
        "matched_patterns": [
          "click"
        ]
      },
      {
        "content": "but now the sky is a reddish color P Labs rolled out a couple new features this week including the Pika scenes which allows you to upload an image of your pet and it will actually turn that image into an AI generated video of your pet doing something interesting they also rolled out this new feature called Peak editions this is where you can give a real life video plus an image and it will take what was in that image and add it to your video like this rabbit we see here or this person opening their laundry where an octopus climbs out here's a a video of a woman with curlers in her hair and then a lion pushes her aside with curlers in his hair so you can see here's people playing basketball here's an image of a bear it puts the Bear in with them somebody opening a door somebody doing yoga with a train behind them so you can basically give it like any video plus an image and it will figure out how to like work that image into the video It's called Peak editions and this little baby popping out of the trash can is probably my favorite scene I've seen from it",
        "matched_patterns": [
          "open"
        ]
      },
      {
        "content": "and then if we look at it again with the person on the right it actually looks like somebody doing gymnastics it figured out the proper physics and how people should move here's another one of somebody doing like a weird ring thing where that doesn't look right but if we go back and look at the updated version on the right you can see it actually figured out how to make it look and this is just again a new way of training these AI video models so they have a much better understanding of the physics and how they should look you're going to see this in a lot of other video models you'll probably see this in cling and Runway and hellu Ai and Pika and all these other tools because with this research they can actually sort of attach this to their existing technology now I'm not going to go too deep into these research papers cuz I actually did a video earlier this week called seven insane AI video breakthroughs you must see I talk about those two papers that I just showed you as well as five other papers that I find really fascinating that have come out within the last couple weeks",
        "matched_patterns": [
          "go to"
        ]
      },
      {
        "content": "so check that out if you want to dive deeper into all of this cool AI research that's coming out that maybe we don't have access to but it's like within weeks maybe months away of it being publicly available for anybody to get their hands on and a couple last real quick things there's a new bill introduced I believe in the Senate that wants to make it illegal to download deep seek with a penalty of up to 20 years in prison now I don't think this thing's everever going to get passed but there are people in the government that want to make it illegal to use some of these open source models it's something to be aware of and in the final bit of news that I'll share this week the Beatles won a Grammy this week for a song that was assisted with AI",
        "matched_patterns": [
          "open"
        ]
      }
    ],
    "developer": [
      {
        "content": "Pro it's good at coding good at software engineering and it's pretty much the most powerful model on the market other than 01 Pro which is only in the $200 a month tier this new 03 mini however is available in every tier and available in the API as well Pro users will have unlimited access to 03 mini and plus and team users will have triple the rate limits versus 01 mini free users can try 03 mini in chat GPT by selecting the reason button under the message composer so even free chat GPT users are getting access to this newest state-of-the-art model from open AI you can even combine this 03 Mini model with their search model even on free plans open AI said try search plus reasoning together in chat GPT free users can use open aai 03 min with search by selecting the search plus reason buttons together",
        "matched_patterns": [
          "api"
        ]
      },
      {
        "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
        "matched_patterns": [
          "api"
        ]
      },
      {
        "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
        "matched_patterns": [
          "api"
        ]
      },
      {
        "content": "so this isn't based on voting this is just based on what is actually getting used right now it's somehow watching the apis and going okay these models are what most people are using and on the day of this recording which is Thursday February 6th Claude Sonet holds the top two spots for the all category section but then Google's Gemini models hold the third and fourth spots so when it comes to usage right now Claude and Gemini are being used more than open AI apis at least today if we look at Top This Week very similar story CLA Claude Gemini Gemini followed by open AI top this month Claude Claude Gemini Gemini",
        "matched_patterns": [
          "api"
        ]
      },
      {
        "content": "and then if we look at trending to see which thing people are switching over to and starting to use more and more of recently look at this number one right here Gemini flash 2.0 this is the most trending model right now and this is all categories if we look at programming we've got CLA Claud flash if we look at technology we've got Claud followed by Flash and if we look at translation Gemini Flash the previous generation of model is number one kind of a cool resource to keep tabs on which AI models are actually getting the most use at the moment but Google had some other news this week for developers that use their API you can now use the Imagine 3 AI image generator from their API and we've looked at imagine 3 quite a bit in previous videos it is a really really solid model in fact if we jump back over to the arena here click on our leaderboard if we check out their text image leaderboard we can actually see that imagine three the model from Google is ranked the top model and these are ranked in the same way you're given two images for a prompt you pick which one you like best it doesn't tell you which model you picked until after you picked it and that's how this stuff gets ranked and imagine three is number one followed by recraft followed by idiogram and so on down the line with stable diffusion falling in last",
        "matched_patterns": [
          "api"
        ]
      },
      {
        "content": "so now I'm going to sort of Rapid Fire a whole bunch of other little things that happen in the world of AI starting with the fact that Mr all AI a sort of competitor to open AI out of France launched a new version of lechette now they've had lechette for a while it's a free chatbot that you can find over at chat.",
        "matched_patterns": [
          "api"
        ]
      },
      {
        "content": "m.ai and it can do a lot of the same things you would get out of chat GPT things like search the web generate images code interpreter and it even has a canvas mode where it'll put any sort of code and writing inside of a canvas very similar to chat GPT they do now have a Pro Plan which I believe is 15 bucks a month",
        "matched_patterns": [
          "code"
        ]
      },
      {
        "content": "so they do have a Pro Plan now available that gives even more access and reduces the limit of messages per day but even the free version is still pretty dang impressive the most impressive part about mraw is how fast it is people have been claiming they're getting a th000 tokens per second output when they ask it a question which is mind-blowingly fast in fact I came across this video from Val on X here who is an intern over at mraw and well just check this out they give it the prompt generate me a kawaii calculator in canvas and we can see that it actually generated everything in like near real time that calculator that popped up that happened in real time I didn't speed up this video they didn't speed up their video they gave it the prompt to generate the kauwaii calculator and it generated the code showed an example of it they started giving it some extra prompts like now make it nature themed and within seconds created a nature themed calculator and it's all like practically instant that's how fast it is and we can see Val here says no this video is not sped up genuinely mind-blowing and it's available to all users right now",
        "matched_patterns": [
          "code"
        ]
      },
      {
        "content": "so it's available for free just to give it my own test I'm going to make sure I have the canvas turned on and I'm going to just type generate a kawaii calculator and we'll see how fast this is I'm not going to speed this up at all this is my own test here and when I press the button I will keep on talking it it wrote All That code practically instantly and that was super fast now it created in HTML",
        "matched_patterns": [
          "code"
        ]
      },
      {
        "content": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat",
        "matched_patterns": [
          "code"
        ]
      },
      {
        "content": "and I don't really know how to code",
        "matched_patterns": [
          "code"
        ]
      },
      {
        "content": "so I made it super super easy to filter them and find the exact tool you're looking for for your needs even put a match pick on here so you can find the tools that I think are the most interesting right now I keep the AI news page up to date on a daily basis I keep it simple and basic and just a list of here's all the important AI news that's happening and if you want to get the latest news and the coolest tools mailed to you twice a week join the free newsletter I'll keep you looped in directly in your inbox and by joining the free newsletter you also get access to the AI income database which is a little database I've been building out of cool ways to make money using the various AI tools that are available again it's all free over at futur tools.",
        "matched_patterns": [
          "import"
        ]
      }
    ],
    "config": [
      {
        "content": "it's like watching somebody use Internet Explorer but in 2025 painfully unnecessary and that's why for this video I partnered with chat base they're revolutionizing the customer experience with AI agents that don't just chat they actually do things for you we're talking AI that can instantly book meetings through calendly create support tickets with zenes or even check realtime data from your own systems what makes this really cool is that these AI agents can be trained on your own business data they're not just giving generic responses they're providing personalized help that actually makes sense it can do things on behalf of your business for your customers things like upgrading their subscription for them adding members to a dashboard for you and checking the limits of their plan all based on your custom workflows plus they work across all your channels from your website to WhatsApp to slack so that your customers can get help wherever they are and the best part you don't need to be a coding wizard to set this up chatbase has made it super simple to set up and manage these AI agents no matter what your technical level is anybody can set these things up if you want to see how chatbase can transform your customer experience from please wait to it's done check out the link in the description trust me your customers are going to thank you for this one and thank you so much to chat base for sponsoring this video there is a little bit of Darker news to come out of Google this week",
        "matched_patterns": [
          "set up"
        ]
      }
    ],
    "troubleshoot": [
      {
        "content": "open AI said updated Chain of Thought in open aai 03 mini for free and paid users and in 03 mini High for paid users now the Chain of Thought that it's showing here isn't actually the true Chain of Thought that's happening it's not like what you see in deep seek R1 where you see literally everything the model's thinking before it gives you the response this gives you sort of like a summarized version of what it's thinking before it gives you a response McKay Wrigley here even argues that it's actually worse than giving us nothing at all he says 03 mini is exceptionally great",
        "matched_patterns": [
          "exception"
        ]
      },
      {
        "content": "but I do worry that summarized Chain of Thought is actually worse than nothing at all true Chain of Thought exposure acts as a prompt debugger it helps us steer the model summarized Chain of Thought up escapes this and potentially adds errors and it makes it harder to debug so if you're looking at something like deep seek R1 and you can see literally everything it's thinking and it gives you an incorrect answer you could literally go back and look through the chain of thought and figure out where it's screwed up these summarized chains of thought that open ai3 is giving us you can't really do that",
        "matched_patterns": [
          "error",
          "debug"
        ]
      },
      {
        "content": "there was a little bit of news out of anthropic this week they gave us an area to try to jailbreak clad and see if we can get it to Output dangerous responses there's eight levels that it goes through and they actually have a bounty where they'll actually pay you if you manage to jailbreak all eight questions so far nobody's managed to do it but there is a little bit of other news around anthropic Lyft is starting to use anthropic clad for their customer service claiming that it reduces the average resolution time for a request by 87%",
        "matched_patterns": [
          "solution"
        ]
      },
      {
        "content": "so if you're using Lyft and you run into issues",
        "matched_patterns": [
          "issue"
        ]
      },
      {
        "content": "and you try to contact customer support it's actually using Claud to sort of help you get through whatever issue you've got we also learned that Amazon Alexa has an event coming up on February 26 Amazon's holding an event and a spokesperson said the event is Alexa focused but then declined to elaborate",
        "matched_patterns": [
          "issue"
        ]
      },
      {
        "content": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat",
        "matched_patterns": [
          "error",
          "fix",
          "catch"
        ]
      },
      {
        "content": "and I think it comes down to the fact that tools like cursor make it so literally anybody on the planet can write little software for themselves I've used it multiple times to solve little problems in my own workflows like I wanted a tool to quickly convert files from any image format into a JPEG I use cursor to create that app in about 15 minutes",
        "matched_patterns": [
          "problem"
        ]
      },
      {
        "content": "but that's Peak Edition something fun to go play around with but I also wanted to show off what came out of topaz labs this week a company that makes a really really good upscaler I use it to upscale images all the time I use it to upscale video footage all the time they actually just released what they call Project Starlight which is the first ever diffusion model for video restoration so it takes old lowquality videos and turns them into high resolution videos so let's take a peek at this video down here of a Muhammad Ali fight you can see on the left how sort of grainy and pixely it is and the one on the right is the more upscaled version that use this project Starlite",
        "matched_patterns": [
          "solution"
        ]
      }
    ]
  },
  "originalPreprocessed": {
    "patterns": {
      "steps": [
        {
          "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
          "context_before": "I'm sure I butchered at least one of those names all joined in on this Reddit AMA a few comments they made they are still planning on doing a 40 image generator so an image generator that's different than DOI",
          "context_after": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
          "position": 25
        },
        {
          "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
          "context_before": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
          "context_after": "so Gemini holds three out of the top five spots right now and the new model from open AI 03 mini Falls all the way down here at 1 2 3 4 5 6 7 8 9 10 the other place I like to look at models is this site open router which I actually learned about from Logan Kilpatrick when he was on our podcast the other day and this is actually looking at Which models are actually getting the most use",
          "position": 27
        },
        {
          "content": "so this isn't based on voting this is just based on what is actually getting used right now it's somehow watching the apis and going okay these models are what most people are using and on the day of this recording which is Thursday February 6th Claude Sonet holds the top two spots for the all category section but then Google's Gemini models hold the third and fourth spots so when it comes to usage right now Claude and Gemini are being used more than open AI apis at least today if we look at Top This Week very similar story CLA Claude Gemini Gemini followed by open AI top this month Claude Claude Gemini Gemini",
          "context_before": "so Gemini holds three out of the top five spots right now and the new model from open AI 03 mini Falls all the way down here at 1 2 3 4 5 6 7 8 9 10 the other place I like to look at models is this site open router which I actually learned about from Logan Kilpatrick when he was on our podcast the other day and this is actually looking at Which models are actually getting the most use",
          "context_after": "and then if we look at trending to see which thing people are switching over to and starting to use more and more of recently look at this number one right here Gemini flash 2.0 this is the most trending model right now and this is all categories if we look at programming we've got CLA Claud flash if we look at technology we've got Claud followed by Flash and if we look at translation Gemini Flash the previous generation of model is number one kind of a cool resource to keep tabs on which AI models are actually getting the most use at the moment but Google had some other news this week for developers that use their API you can now use the Imagine 3 AI image generator from their API and we've looked at imagine 3 quite a bit in previous videos it is a really really solid model in fact if we jump back over to the arena here click on our leaderboard if we check out their text image leaderboard we can actually see that imagine three the model from Google is ranked the top model and these are ranked in the same way you're given two images for a prompt you pick which one you like best it doesn't tell you which model you picked until after you picked it and that's how this stuff gets ranked and imagine three is number one followed by recraft followed by idiogram and so on down the line with stable diffusion falling in last",
          "position": 29
        },
        {
          "content": "goole.com another cool resource for you you know that feeling you're trying to get help from a company and you end up stuck in this endless loop of let me transfer you to the right person or we'll get back to you at 24 to 48 hours and even when you finally do get help they still need to do manual things like check your order status or schedule a meeting with you",
          "context_before": "google.com over on the right you have the option to select from various models to use and this is totally free right now you've got Gemini 2.0 flash flashlight Pro experimental flash thinking plus all of their previous models and their open source models all available for you to play with and enter prompts here and we can see we've got over a million context window as well all totally free to use over at aist studio.",
          "context_after": "it's like watching somebody use Internet Explorer but in 2025 painfully unnecessary and that's why for this video I partnered with chat base they're revolutionizing the customer experience with AI agents that don't just chat they actually do things for you we're talking AI that can instantly book meetings through calendly create support tickets with zenes or even check realtime data from your own systems what makes this really cool is that these AI agents can be trained on your own business data they're not just giving generic responses they're providing personalized help that actually makes sense it can do things on behalf of your business for your customers things like upgrading their subscription for them adding members to a dashboard for you and checking the limits of their plan all based on your custom workflows plus they work across all your channels from your website to WhatsApp to slack so that your customers can get help wherever they are and the best part you don't need to be a coding wizard to set this up chatbase has made it super simple to set up and manage these AI agents no matter what your technical level is anybody can set these things up if you want to see how chatbase can transform your customer experience from please wait to it's done check out the link in the description trust me your customers are going to thank you for this one and thank you so much to chat base for sponsoring this video there is a little bit of Darker news to come out of Google this week",
          "position": 36
        },
        {
          "content": "so they do have a Pro Plan now available that gives even more access and reduces the limit of messages per day but even the free version is still pretty dang impressive the most impressive part about mraw is how fast it is people have been claiming they're getting a th000 tokens per second output when they ask it a question which is mind-blowingly fast in fact I came across this video from Val on X here who is an intern over at mraw and well just check this out they give it the prompt generate me a kawaii calculator in canvas and we can see that it actually generated everything in like near real time that calculator that popped up that happened in real time I didn't speed up this video they didn't speed up their video they gave it the prompt to generate the kauwaii calculator and it generated the code showed an example of it they started giving it some extra prompts like now make it nature themed and within seconds created a nature themed calculator and it's all like practically instant that's how fast it is and we can see Val here says no this video is not sped up genuinely mind-blowing and it's available to all users right now",
          "context_before": "yeah",
          "context_after": "so it's available for free just to give it my own test I'm going to make sure I have the canvas turned on and I'm going to just type generate a kawaii calculator and we'll see how fast this is I'm not going to speed this up at all this is my own test here and when I press the button I will keep on talking it it wrote All That code practically instantly and that was super fast now it created in HTML",
          "position": 46
        },
        {
          "content": "so this calculator actually works uh it's pink and yellow and it generated it in 2 seconds maybe mind-blowingly fast again totally free chat.",
          "context_before": "so let's just double check to see how it did and here's the calculator that it generated let's actually see if it works 9 + 9 = 18 18 * 2 equal 36",
          "context_after": "mall.",
          "position": 49
        },
        {
          "content": "and I threw in an image of a wolf howling at the moon let's just see what happens when we try to blend those two together and my first attempt did not work at all it kind of made my face look a little more AI generated but it didn't add the wolf Hing at the Moon let's add a dut and see what happens",
          "context_before": "so I uploaded a quick video of me talking in front of my camera here",
          "context_after": "and well this time I can definitely see it added a doughnut in let's see what it looks like so it pretty much just put the dut in the corner of the video I guess you probably need a video with a little more action going on than me just you know talking into the camera like this",
          "position": 71
        },
        {
          "content": "but that's Peak Edition something fun to go play around with but I also wanted to show off what came out of topaz labs this week a company that makes a really really good upscaler I use it to upscale images all the time I use it to upscale video footage all the time they actually just released what they call Project Starlight which is the first ever diffusion model for video restoration so it takes old lowquality videos and turns them into high resolution videos so let's take a peek at this video down here of a Muhammad Ali fight you can see on the left how sort of grainy and pixely it is and the one on the right is the more upscaled version that use this project Starlite",
          "context_before": "and well this time I can definitely see it added a doughnut in let's see what it looks like so it pretty much just put the dut in the corner of the video I guess you probably need a video with a little more action going on than me just you know talking into the camera like this",
          "context_after": "and it's pretty impressive how much higher quality",
          "position": 73
        },
        {
          "content": "so I'll link it up in the description if you want to get involved there's also some really cool research that came out this week like this omnium one which is basically a tool where where you can give it a single image and an audio file and it will combine them to make like a deep fake so check this out here's like a 10-second clip of one the first frame was the image that they uploaded and then the audio you're going to hear was the audio they uploaded and it turned it into a deep fake of that person talking give people Something to Believe In and they will move from you and me to us and here's another one with Einstein what would art be like without emotions it would be empty what would our lives be like without emotions they would be empty of values so we're at a point now where you can just have an image of a person a sound bite from that person that could even be made in 11 Labs so it could be something that they never actually said and you can combine those two and make like a deep fake with them that's omnium one",
          "context_before": "and uh you got to like and comment to get access",
          "context_after": "and then there's also this one called video Jam which is like a new way of training video models that make them so much more coherent like we can see gymnastics what it looks like from most videos on the left here",
          "position": 77
        },
        {
          "content": "and that's what I got for you today again another week with tons of news I mentioned it's not going to slow down anytime soon it didn't slow down this week I doubt it's going to slow down next week",
          "context_before": "so that's pretty cool",
          "context_after": "so if if you want to make sure you stay looped in on all of the latest AI news I make a breakdown video every single Friday where I try to cover all of the news that I think is worth talking about from the past week in the world of AI I also like to create tutorials and talk about different tools and research that are coming out in the AI world",
          "position": 83
        },
        {
          "content": "so if you have feedback for me I love to hear it put it in the comments I really really appreciate anything you guys put in the comments All actually useful feedback is really really valuable to me and finally before I go I should remind you to check out futur tools.",
          "context_before": "so if that's the kind of stuff you're into give this video a like and maybe consider subscribing to this channel that'll make sure more stuff like this shows up in your YouTube feed I've also been doing some experimenting with the channel you'll probably notice I've been testing new thumbnails Styles and new titling Styles and new video Styles and things like that",
          "context_after": "this is the site that I built where I share all the cool AI tools I come across I add tons of new tools every single day there are just so many AI tools",
          "position": 86
        },
        {
          "content": "thank you so much again for tuning in thank you for nerding out with me today thanks so much to chatbase for sponsoring this video really appreciate all of you for tuning in and I will hopefully see you in the next one bye-bye",
          "context_before": "so I made it super super easy to filter them and find the exact tool you're looking for for your needs even put a match pick on here so you can find the tools that I think are the most interesting right now I keep the AI news page up to date on a daily basis I keep it simple and basic and just a list of here's all the important AI news that's happening and if you want to get the latest news and the coolest tools mailed to you twice a week join the free newsletter I'll keep you looped in directly in your inbox and by joining the free newsletter you also get access to the AI income database which is a little database I've been building out of cool ways to make money using the various AI tools that are available again it's all free over at futur tools.",
          "context_after": "",
          "position": 89
        }
      ],
      "examples": [
        {
          "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
          "context_before": "I'm sure I butchered at least one of those names all joined in on this Reddit AMA a few comments they made they are still planning on doing a 40 image generator so an image generator that's different than DOI",
          "context_after": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
          "position": 25
        },
        {
          "content": "but now the sky is a reddish color P Labs rolled out a couple new features this week including the Pika scenes which allows you to upload an image of your pet and it will actually turn that image into an AI generated video of your pet doing something interesting they also rolled out this new feature called Peak editions this is where you can give a real life video plus an image and it will take what was in that image and add it to your video like this rabbit we see here or this person opening their laundry where an octopus climbs out here's a a video of a woman with curlers in her hair and then a lion pushes her aside with curlers in his hair so you can see here's people playing basketball here's an image of a bear it puts the Bear in with them somebody opening a door somebody doing yoga with a train behind them so you can basically give it like any video plus an image and it will figure out how to like work that image into the video It's called Peak editions and this little baby popping out of the trash can is probably my favorite scene I've seen from it",
          "context_before": "and you can see we get pretty much the same image composition back",
          "context_after": "but if we head on over to p. art we can see down in the bottom we have a few new buttons like Pika scenes and Peak addition",
          "position": 66
        },
        {
          "content": "and well this time I can definitely see it added a doughnut in let's see what it looks like so it pretty much just put the dut in the corner of the video I guess you probably need a video with a little more action going on than me just you know talking into the camera like this",
          "context_before": "and I threw in an image of a wolf howling at the moon let's just see what happens when we try to blend those two together and my first attempt did not work at all it kind of made my face look a little more AI generated but it didn't add the wolf Hing at the Moon let's add a dut and see what happens",
          "context_after": "but that's Peak Edition something fun to go play around with but I also wanted to show off what came out of topaz labs this week a company that makes a really really good upscaler I use it to upscale images all the time I use it to upscale video footage all the time they actually just released what they call Project Starlight which is the first ever diffusion model for video restoration so it takes old lowquality videos and turns them into high resolution videos so let's take a peek at this video down here of a Muhammad Ali fight you can see on the left how sort of grainy and pixely it is and the one on the right is the more upscaled version that use this project Starlite",
          "position": 72
        },
        {
          "content": "so I'll link it up in the description if you want to get involved there's also some really cool research that came out this week like this omnium one which is basically a tool where where you can give it a single image and an audio file and it will combine them to make like a deep fake so check this out here's like a 10-second clip of one the first frame was the image that they uploaded and then the audio you're going to hear was the audio they uploaded and it turned it into a deep fake of that person talking give people Something to Believe In and they will move from you and me to us and here's another one with Einstein what would art be like without emotions it would be empty what would our lives be like without emotions they would be empty of values so we're at a point now where you can just have an image of a person a sound bite from that person that could even be made in 11 Labs so it could be something that they never actually said and you can combine those two and make like a deep fake with them that's omnium one",
          "context_before": "and uh you got to like and comment to get access",
          "context_after": "and then there's also this one called video Jam which is like a new way of training video models that make them so much more coherent like we can see gymnastics what it looks like from most videos on the left here",
          "position": 77
        },
        {
          "content": "so if that's the kind of stuff you're into give this video a like and maybe consider subscribing to this channel that'll make sure more stuff like this shows up in your YouTube feed I've also been doing some experimenting with the channel you'll probably notice I've been testing new thumbnails Styles and new titling Styles and new video Styles and things like that",
          "context_before": "so if if you want to make sure you stay looped in on all of the latest AI news I make a breakdown video every single Friday where I try to cover all of the news that I think is worth talking about from the past week in the world of AI I also like to create tutorials and talk about different tools and research that are coming out in the AI world",
          "context_after": "so if you have feedback for me I love to hear it put it in the comments I really really appreciate anything you guys put in the comments All actually useful feedback is really really valuable to me and finally before I go I should remind you to check out futur tools.",
          "position": 85
        }
      ],
      "key_points": [
        {
          "content": "yes only a single digit meaning you know between 1 and 9% but that single digigit percentage still likely adds up to billions of dollars worth of value that this deep research is capable of doing and not only that but Sam te's that there's still something else coming he said note this is not the one more thing for 03 mini a few more days for that and he said that on the same day that deep research came out he was commenting that 03 mini came out and then oh here's deep research which makes all of this stuff even better and we still have one more thing to show you which is exciting but we're not telling you yet but open AI wasn't even done there with announcements this week they had a handful of smaller announcements like the fact that chat GPT search is now a available to everyone over on chat gp.com no sign up required",
          "context_before": "I have ever tried it is absolutely insane because it does the research for you using the Deep research so it will go off on the web and search out items for you as part of the research and then it uses the 01 Pros reasoning to really really think through everything that it came back with and that's how I got that insane detailed report on what I should do on my YouTube channel it wasn't only using what was in its training data it literally did the research did the Chain of Thought reasoning and then spit back out that entire report that's what makes it so powerful is when you start combining all of these things they all combine for an insanely powerful experience where the output is just mindblowing and even if you're in the EU you also get access to deep research deep research is now rolled out to 100% of All Pro users including in the UK EU Norway Iceland lonstein and Switzerland and one interesting thing that Sam Alman said not long after this came out my very approximate Vibe is that it can do a single digit percentage of all economically valuable tasks in the world which is a wild Milestone",
          "context_after": "so if you don't want to use Google search anymore you'd rather use chat GPT for your search you can just go to chat gp.com and do web searches that are combined with AI now without even logging in so now it's like an actual true competitor to what perplexity is doing they also increase the memory limit in chat GPT for plus pro and team users by 25%",
          "position": 20
        },
        {
          "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
          "context_before": "I'm sure I butchered at least one of those names all joined in on this Reddit AMA a few comments they made they are still planning on doing a 40 image generator so an image generator that's different than DOI",
          "context_after": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
          "position": 25
        },
        {
          "content": "so I made it super super easy to filter them and find the exact tool you're looking for for your needs even put a match pick on here so you can find the tools that I think are the most interesting right now I keep the AI news page up to date on a daily basis I keep it simple and basic and just a list of here's all the important AI news that's happening and if you want to get the latest news and the coolest tools mailed to you twice a week join the free newsletter I'll keep you looped in directly in your inbox and by joining the free newsletter you also get access to the AI income database which is a little database I've been building out of cool ways to make money using the various AI tools that are available again it's all free over at futur tools.",
          "context_before": "this is the site that I built where I share all the cool AI tools I come across I add tons of new tools every single day there are just so many AI tools",
          "context_after": "thank you so much again for tuning in thank you for nerding out with me today thanks so much to chatbase for sponsoring this video really appreciate all of you for tuning in and I will hopefully see you in the next one bye-bye",
          "position": 88
        }
      ],
      "lists": [],
      "code_blocks": []
    },
    "semantic": {
      "actions": [
        {
          "content": "and I don't want to waste your time",
          "importance": 0.1132713183760643
        },
        {
          "content": "so let's get into this week's AI news breakdown starting with news that actually came out last week",
          "importance": 0.2361585795879364
        },
        {
          "content": "but I record these videos on Thursdays and this news came out on Friday of last week it was when open AI released their 03 mini now we did talk about it in last Friday's video because we knew it was going to come out on Friday but now that we actually have access to it I figured let's talk about it real quick this new 03 model outperforms pretty much every other model out there in math except for 01 Pro which is not actually listed on this chart in PhD level science questions the 03 mini High version beats everything else that's out there except for of course 01",
          "importance": 0.25234946608543396
        },
        {
          "content": "but I do worry that summarized Chain of Thought is actually worse than nothing at all true Chain of Thought exposure acts as a prompt debugger it helps us steer the model summarized Chain of Thought up escapes this and potentially adds errors and it makes it harder to debug so if you're looking at something like deep seek R1 and you can see literally everything it's thinking and it gives you an incorrect answer you could literally go back and look through the chain of thought and figure out where it's screwed up these summarized chains of thought that open ai3 is giving us you can't really do that",
          "importance": 0.18715636432170868
        },
        {
          "content": "but in my opinion the even bigger news that came out from open AI this week wasn't even the fact that they gave us 03 mini on Friday it was that over the weekend they gave us deep research unfortunately deep research is only available to Pro users on the $200 a month plan which I do know makes it economically infeasible for a lot of people",
          "importance": 0.27992498874664307
        },
        {
          "content": "it is kind of interesting that they named it deep research because Google has a product called Gemini with deep research it's exactly the same naming scheme which is definitely going to confuse people but it does work really",
          "importance": 0.19970372319221497
        },
        {
          "content": "well I asked deep research to help me with a YouTube strategy it actually gave me some follow-up questions so that it can better understand what I was trying to accomplish like my current strategy on long form versus short form videos my current video length and format how I decide on tutorials like what my competitors are doing what my monetization focuses are things like that I answered its questions",
          "importance": 0.18506883084774017
        },
        {
          "content": "and then it gave me just an absolute Beast of a write up of how I should manage my YouTube channel and it is really really really indepth and honestly created an amazing killer strategy like I'm literally following through on this strategy with my YouTube channel now it wrote up this giant essay here",
          "importance": 0.17712484300136566
        },
        {
          "content": "and I actually pasted it back into chat GPT this is the entire write up that it gave me I pasted it back into GPT 40 and asked it to give me a stepbystep checklist and you can see here that it simplified everything and gave me a checklist of what to do for my Channel even gave me a 4-week breakdown to dial it all in so deep research has been a game Cher for me",
          "importance": 0.2014639675617218
        },
        {
          "content": "I know it's on the $200 a month plan but had I hired like a YouTube consultant to look at my channel analyze everything I was doing and give me a detailed like 10 page Report with a step-by-step checklist of what I need to do on the channel they would have charged me way more than $200 so I feel like I got the value out of that from that alone",
          "importance": 0.17745819687843323
        },
        {
          "content": "but I also don't want you to feel like I'm trying to sell you on getting the $200 month plan for most people it's probably still not worth it",
          "importance": 0.09457724541425705
        },
        {
          "content": "I've just personally found a lot of value from it there's a recent benchmark test that came out titled Humanity's last exam and you can see how some of the other existing models performed on this benchmark test GPT 40 got a 3.3% in accuracy open eyes 01 got a 9.1 deep seek R1 got a 9.4 the new openai 03 mini High got a 13.0 open AI with deep research got a 26 .6% on the accuracy if you have a pro account if you combind 01 Pro with deep research it is hands down the most powerful AI large language model",
          "importance": 0.22015787661075592
        },
        {
          "content": "I have ever tried it is absolutely insane because it does the research for you using the Deep research so it will go off on the web and search out items for you as part of the research and then it uses the 01 Pros reasoning to really really think through everything that it came back with and that's how I got that insane detailed report on what I should do on my YouTube channel it wasn't only using what was in its training data it literally did the research did the Chain of Thought reasoning and then spit back out that entire report that's what makes it so powerful is when you start combining all of these things they all combine for an insanely powerful experience where the output is just mindblowing and even if you're in the EU you also get access to deep research deep research is now rolled out to 100% of All Pro users including in the UK EU Norway Iceland lonstein and Switzerland and one interesting thing that Sam Alman said not long after this came out my very approximate Vibe is that it can do a single digit percentage of all economically valuable tasks in the world which is a wild Milestone",
          "importance": 0.2344619780778885
        },
        {
          "content": "yes only a single digit meaning you know between 1 and 9% but that single digigit percentage still likely adds up to billions of dollars worth of value that this deep research is capable of doing and not only that but Sam te's that there's still something else coming he said note this is not the one more thing for 03 mini a few more days for that and he said that on the same day that deep research came out he was commenting that 03 mini came out and then oh here's deep research which makes all of this stuff even better and we still have one more thing to show you which is exciting but we're not telling you yet but open AI wasn't even done there with announcements this week they had a handful of smaller announcements like the fact that chat GPT search is now a available to everyone over on chat gp.com no sign up required",
          "importance": 0.2840880751609802
        },
        {
          "content": "so if you don't want to use Google search anymore you'd rather use chat GPT for your search you can just go to chat gp.com and do web searches that are combined with AI now without even logging in so now it's like an actual true competitor to what perplexity is doing they also increase the memory limit in chat GPT for plus pro and team users by 25%",
          "importance": 0.24139338731765747
        },
        {
          "content": "yeah it's been a big week for open Ai and since open AI had so much going on this week they actually took to Reddit to do an AMA where Sam Alman Mark Chen Kevin wheel serenos nanian Michelle Pocas and hungu ren",
          "importance": 0.23442082107067108
        },
        {
          "content": "I'm sure I butchered at least one of those names all joined in on this Reddit AMA a few comments they made they are still planning on doing a 40 image generator so an image generator that's different than DOI",
          "importance": 0.1813376098871231
        },
        {
          "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
          "importance": 0.2657625079154968
        },
        {
          "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
          "importance": 0.18657425045967102
        },
        {
          "content": "so Gemini holds three out of the top five spots right now and the new model from open AI 03 mini Falls all the way down here at 1 2 3 4 5 6 7 8 9 10 the other place I like to look at models is this site open router which I actually learned about from Logan Kilpatrick when he was on our podcast the other day and this is actually looking at Which models are actually getting the most use",
          "importance": 0.17645390331745148
        },
        {
          "content": "so this isn't based on voting this is just based on what is actually getting used right now it's somehow watching the apis and going okay these models are what most people are using and on the day of this recording which is Thursday February 6th Claude Sonet holds the top two spots for the all category section but then Google's Gemini models hold the third and fourth spots so when it comes to usage right now Claude and Gemini are being used more than open AI apis at least today if we look at Top This Week very similar story CLA Claude Gemini Gemini followed by open AI top this month Claude Claude Gemini Gemini",
          "importance": 0.26780012249946594
        },
        {
          "content": "and then if we look at trending to see which thing people are switching over to and starting to use more and more of recently look at this number one right here Gemini flash 2.0 this is the most trending model right now and this is all categories if we look at programming we've got CLA Claud flash if we look at technology we've got Claud followed by Flash and if we look at translation Gemini Flash the previous generation of model is number one kind of a cool resource to keep tabs on which AI models are actually getting the most use at the moment but Google had some other news this week for developers that use their API you can now use the Imagine 3 AI image generator from their API and we've looked at imagine 3 quite a bit in previous videos it is a really really solid model in fact if we jump back over to the arena here click on our leaderboard if we check out their text image leaderboard we can actually see that imagine three the model from Google is ranked the top model and these are ranked in the same way you're given two images for a prompt you pick which one you like best it doesn't tell you which model you picked until after you picked it and that's how this stuff gets ranked and imagine three is number one followed by recraft followed by idiogram and so on down the line with stable diffusion falling in last",
          "importance": 0.2901161313056946
        },
        {
          "content": "but if you're a developer and you want to use this model within your workflow you now have access to it if you're not a developer and you want to play with imagine 3 the best way to do it is over in Google Labs over at labs.",
          "importance": 0.17067064344882965
        },
        {
          "content": "google.com over on the right you have the option to select from various models to use and this is totally free right now you've got Gemini 2.0 flash flashlight Pro experimental flash thinking plus all of their previous models and their open source models all available for you to play with and enter prompts here and we can see we've got over a million context window as well all totally free to use over at aist studio.",
          "importance": 0.2063865065574646
        },
        {
          "content": "goole.com another cool resource for you you know that feeling you're trying to get help from a company and you end up stuck in this endless loop of let me transfer you to the right person or we'll get back to you at 24 to 48 hours and even when you finally do get help they still need to do manual things like check your order status or schedule a meeting with you",
          "importance": 0.11206184327602386
        },
        {
          "content": "it's like watching somebody use Internet Explorer but in 2025 painfully unnecessary and that's why for this video I partnered with chat base they're revolutionizing the customer experience with AI agents that don't just chat they actually do things for you we're talking AI that can instantly book meetings through calendly create support tickets with zenes or even check realtime data from your own systems what makes this really cool is that these AI agents can be trained on your own business data they're not just giving generic responses they're providing personalized help that actually makes sense it can do things on behalf of your business for your customers things like upgrading their subscription for them adding members to a dashboard for you and checking the limits of their plan all based on your custom workflows plus they work across all your channels from your website to WhatsApp to slack so that your customers can get help wherever they are and the best part you don't need to be a coding wizard to set this up chatbase has made it super simple to set up and manage these AI agents no matter what your technical level is anybody can set these things up if you want to see how chatbase can transform your customer experience from please wait to it's done check out the link in the description trust me your customers are going to thank you for this one and thank you so much to chat base for sponsoring this video there is a little bit of Darker news to come out of Google this week",
          "importance": 0.24828585982322693
        },
        {
          "content": "m.ai and it can do a lot of the same things you would get out of chat GPT things like search the web generate images code interpreter and it even has a canvas mode where it'll put any sort of code and writing inside of a canvas very similar to chat GPT they do now have a Pro Plan which I believe is 15 bucks a month",
          "importance": 0.2764517664909363
        },
        {
          "content": "so they do have a Pro Plan now available that gives even more access and reduces the limit of messages per day but even the free version is still pretty dang impressive the most impressive part about mraw is how fast it is people have been claiming they're getting a th000 tokens per second output when they ask it a question which is mind-blowingly fast in fact I came across this video from Val on X here who is an intern over at mraw and well just check this out they give it the prompt generate me a kawaii calculator in canvas and we can see that it actually generated everything in like near real time that calculator that popped up that happened in real time I didn't speed up this video they didn't speed up their video they gave it the prompt to generate the kauwaii calculator and it generated the code showed an example of it they started giving it some extra prompts like now make it nature themed and within seconds created a nature themed calculator and it's all like practically instant that's how fast it is and we can see Val here says no this video is not sped up genuinely mind-blowing and it's available to all users right now",
          "importance": 0.27121978998184204
        },
        {
          "content": "so it's available for free just to give it my own test I'm going to make sure I have the canvas turned on and I'm going to just type generate a kawaii calculator and we'll see how fast this is I'm not going to speed this up at all this is my own test here and when I press the button I will keep on talking it it wrote All That code practically instantly and that was super fast now it created in HTML",
          "importance": 0.1921951323747635
        },
        {
          "content": "so let's just double check to see how it did and here's the calculator that it generated let's actually see if it works 9 + 9 = 18 18 * 2 equal 36",
          "importance": 0.07883941382169724
        },
        {
          "content": "there was a little bit of news out of anthropic this week they gave us an area to try to jailbreak clad and see if we can get it to Output dangerous responses there's eight levels that it goes through and they actually have a bounty where they'll actually pay you if you manage to jailbreak all eight questions so far nobody's managed to do it but there is a little bit of other news around anthropic Lyft is starting to use anthropic clad for their customer service claiming that it reduces the average resolution time for a request by 87%",
          "importance": 0.13830210268497467
        },
        {
          "content": "so if you're using Lyft and you run into issues",
          "importance": 0.08756550401449203
        },
        {
          "content": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat",
          "importance": 0.168312668800354
        },
        {
          "content": "I've personally never used GitHub co-pilot I've been much more on the cursor train myself",
          "importance": 0.19514645636081696
        },
        {
          "content": "but this sounds really really handy for it to sort of double check its own work and pull stuff in from the terminal when something's not working properly that just sounds like great quality of life updates that I imagine tools like cursor will get as well and since we mentioned cursor I want to point this out real quick cuz I found it fascinating that cursor is literally the fastest growing SAS company in the history of SAS",
          "importance": 0.17942434549331665
        },
        {
          "content": "so SAS is software as a service and if we look at this chart here we can see this is cursor's growth curve it basically took one year to get to 100 million in annual recurring Revenue we can wise deal together AI Core weave open Ai and DocuSign and all of their respective charts it took docine 10 years to get to 100 million in annual recurring Revenue it took cursor only one year that's pretty mind-blowing how quickly cursor is growing",
          "importance": 0.21908412873744965
        },
        {
          "content": "and I think it comes down to the fact that tools like cursor make it so literally anybody on the planet can write little software for themselves I've used it multiple times to solve little problems in my own workflows like I wanted a tool to quickly convert files from any image format into a JPEG I use cursor to create that app in about 15 minutes",
          "importance": 0.1667919158935547
        },
        {
          "content": "and now I have a simple workflow where whenever I grab an image from any app or download on the Internet or anything I don't have to open it up in like a photos app",
          "importance": 0.09081941097974777
        },
        {
          "content": "and I don't really know how to code",
          "importance": 0.12127552181482315
        },
        {
          "content": "but now the sky is a reddish color P Labs rolled out a couple new features this week including the Pika scenes which allows you to upload an image of your pet and it will actually turn that image into an AI generated video of your pet doing something interesting they also rolled out this new feature called Peak editions this is where you can give a real life video plus an image and it will take what was in that image and add it to your video like this rabbit we see here or this person opening their laundry where an octopus climbs out here's a a video of a woman with curlers in her hair and then a lion pushes her aside with curlers in his hair so you can see here's people playing basketball here's an image of a bear it puts the Bear in with them somebody opening a door somebody doing yoga with a train behind them so you can basically give it like any video plus an image and it will figure out how to like work that image into the video It's called Peak editions and this little baby popping out of the trash can is probably my favorite scene I've seen from it",
          "importance": 0.21098895370960236
        },
        {
          "content": "but if we head on over to p. art we can see down in the bottom we have a few new buttons like Pika scenes and Peak addition",
          "importance": 0.20980238914489746
        },
        {
          "content": "so if we do Pika scenes I can throw in a picture of my dog here give it a prompt like the pet is flying on a private jet and here's the video we got out of it with my dog flying on a private plane actually looks pretty good kind of looks like him other than the fact that like his back legs don't move properly when he's walking around uh it actually got the face and head looking pretty accurate honestly",
          "importance": 0.1263890564441681
        },
        {
          "content": "and well this time I can definitely see it added a doughnut in let's see what it looks like so it pretty much just put the dut in the corner of the video I guess you probably need a video with a little more action going on than me just you know talking into the camera like this",
          "importance": 0.16110770404338837
        },
        {
          "content": "but that's Peak Edition something fun to go play around with but I also wanted to show off what came out of topaz labs this week a company that makes a really really good upscaler I use it to upscale images all the time I use it to upscale video footage all the time they actually just released what they call Project Starlight which is the first ever diffusion model for video restoration so it takes old lowquality videos and turns them into high resolution videos so let's take a peek at this video down here of a Muhammad Ali fight you can see on the left how sort of grainy and pixely it is and the one on the right is the more upscaled version that use this project Starlite",
          "importance": 0.17752788960933685
        },
        {
          "content": "so I'll link it up in the description if you want to get involved there's also some really cool research that came out this week like this omnium one which is basically a tool where where you can give it a single image and an audio file and it will combine them to make like a deep fake so check this out here's like a 10-second clip of one the first frame was the image that they uploaded and then the audio you're going to hear was the audio they uploaded and it turned it into a deep fake of that person talking give people Something to Believe In and they will move from you and me to us and here's another one with Einstein what would art be like without emotions it would be empty what would our lives be like without emotions they would be empty of values so we're at a point now where you can just have an image of a person a sound bite from that person that could even be made in 11 Labs so it could be something that they never actually said and you can combine those two and make like a deep fake with them that's omnium one",
          "importance": 0.18070411682128906
        },
        {
          "content": "and then if we look at it again with the person on the right it actually looks like somebody doing gymnastics it figured out the proper physics and how people should move here's another one of somebody doing like a weird ring thing where that doesn't look right but if we go back and look at the updated version on the right you can see it actually figured out how to make it look and this is just again a new way of training these AI video models so they have a much better understanding of the physics and how they should look you're going to see this in a lot of other video models you'll probably see this in cling and Runway and hellu Ai and Pika and all these other tools because with this research they can actually sort of attach this to their existing technology now I'm not going to go too deep into these research papers cuz I actually did a video earlier this week called seven insane AI video breakthroughs you must see I talk about those two papers that I just showed you as well as five other papers that I find really fascinating that have come out within the last couple weeks",
          "importance": 0.2695239186286926
        },
        {
          "content": "so check that out if you want to dive deeper into all of this cool AI research that's coming out that maybe we don't have access to but it's like within weeks maybe months away of it being publicly available for anybody to get their hands on and a couple last real quick things there's a new bill introduced I believe in the Senate that wants to make it illegal to download deep seek with a penalty of up to 20 years in prison now I don't think this thing's everever going to get passed but there are people in the government that want to make it illegal to use some of these open source models it's something to be aware of and in the final bit of news that I'll share this week the Beatles won a Grammy this week for a song that was assisted with AI",
          "importance": 0.26410508155822754
        },
        {
          "content": "and that's what I got for you today again another week with tons of news I mentioned it's not going to slow down anytime soon it didn't slow down this week I doubt it's going to slow down next week",
          "importance": 0.15438756346702576
        },
        {
          "content": "so if if you want to make sure you stay looped in on all of the latest AI news I make a breakdown video every single Friday where I try to cover all of the news that I think is worth talking about from the past week in the world of AI I also like to create tutorials and talk about different tools and research that are coming out in the AI world",
          "importance": 0.2542753517627716
        },
        {
          "content": "so if that's the kind of stuff you're into give this video a like and maybe consider subscribing to this channel that'll make sure more stuff like this shows up in your YouTube feed I've also been doing some experimenting with the channel you'll probably notice I've been testing new thumbnails Styles and new titling Styles and new video Styles and things like that",
          "importance": 0.17693102359771729
        },
        {
          "content": "so if you have feedback for me I love to hear it put it in the comments I really really appreciate anything you guys put in the comments All actually useful feedback is really really valuable to me and finally before I go I should remind you to check out futur tools.",
          "importance": 0.19497254490852356
        }
      ],
      "problems": [
        {
          "problem": "so if you're using Lyft and you run into issues",
          "solution": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat"
        },
        {
          "problem": "and you try to contact customer support it's actually using Claud to sort of help you get through whatever issue you've got we also learned that Amazon Alexa has an event coming up on February 26 Amazon's holding an event and a spokesperson said the event is Alexa focused but then declined to elaborate",
          "solution": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat"
        }
      ],
      "comparisons": [
        {
          "content": "open AI said updated Chain of Thought in open aai 03 mini for free and paid users and in 03 mini High for paid users now the Chain of Thought that it's showing here isn't actually the true Chain of Thought that's happening it's not like what you see in deep seek R1 where you see literally everything the model's thinking before it gives you the response this gives you sort of like a summarized version of what it's thinking before it gives you a response McKay Wrigley here even argues that it's actually worse than giving us nothing at all he says 03 mini is exceptionally great",
          "context": "and I guess when it was originally released for free members it didn't actually show The Chain of Thought but as of February 6th even that's been updated for both free and paid users"
        },
        {
          "content": "but I do worry that summarized Chain of Thought is actually worse than nothing at all true Chain of Thought exposure acts as a prompt debugger it helps us steer the model summarized Chain of Thought up escapes this and potentially adds errors and it makes it harder to debug so if you're looking at something like deep seek R1 and you can see literally everything it's thinking and it gives you an incorrect answer you could literally go back and look through the chain of thought and figure out where it's screwed up these summarized chains of thought that open ai3 is giving us you can't really do that",
          "context": "open AI said updated Chain of Thought in open aai 03 mini for free and paid users and in 03 mini High for paid users now the Chain of Thought that it's showing here isn't actually the true Chain of Thought that's happening it's not like what you see in deep seek R1 where you see literally everything the model's thinking before it gives you the response this gives you sort of like a summarized version of what it's thinking before it gives you a response McKay Wrigley here even argues that it's actually worse than giving us nothing at all he says 03 mini is exceptionally great"
        },
        {
          "content": "well I asked deep research to help me with a YouTube strategy it actually gave me some follow-up questions so that it can better understand what I was trying to accomplish like my current strategy on long form versus short form videos my current video length and format how I decide on tutorials like what my competitors are doing what my monetization focuses are things like that I answered its questions",
          "context": "it is kind of interesting that they named it deep research because Google has a product called Gemini with deep research it's exactly the same naming scheme which is definitely going to confuse people but it does work really"
        },
        {
          "content": "yes only a single digit meaning you know between 1 and 9% but that single digigit percentage still likely adds up to billions of dollars worth of value that this deep research is capable of doing and not only that but Sam te's that there's still something else coming he said note this is not the one more thing for 03 mini a few more days for that and he said that on the same day that deep research came out he was commenting that 03 mini came out and then oh here's deep research which makes all of this stuff even better and we still have one more thing to show you which is exciting but we're not telling you yet but open AI wasn't even done there with announcements this week they had a handful of smaller announcements like the fact that chat GPT search is now a available to everyone over on chat gp.com no sign up required",
          "context": "I have ever tried it is absolutely insane because it does the research for you using the Deep research so it will go off on the web and search out items for you as part of the research and then it uses the 01 Pros reasoning to really really think through everything that it came back with and that's how I got that insane detailed report on what I should do on my YouTube channel it wasn't only using what was in its training data it literally did the research did the Chain of Thought reasoning and then spit back out that entire report that's what makes it so powerful is when you start combining all of these things they all combine for an insanely powerful experience where the output is just mindblowing and even if you're in the EU you also get access to deep research deep research is now rolled out to 100% of All Pro users including in the UK EU Norway Iceland lonstein and Switzerland and one interesting thing that Sam Alman said not long after this came out my very approximate Vibe is that it can do a single digit percentage of all economically valuable tasks in the world which is a wild Milestone"
        },
        {
          "content": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break",
          "context": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs"
        },
        {
          "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
          "context": "and so I guess if you're comparing it to Gemini 2.0 flash it's actually 40 cents per million tokens for the output compared to $15 per million tokens for output still quite a bit of a uh price break"
        },
        {
          "content": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat",
          "context": "so really all we know is that they have an event coming up they're going to be talking about Alexa and most people believe that they're going to roll out Alexa with a much smarter AI Amazon said in the past that their AI in Alexa is going to be powered by anthropics Claud"
        },
        {
          "content": "it is here's another example where we can see the side by side of what looks like was recorded on a VHS tape to something that looks quite a bit better quality here it looks like it's an early access right now",
          "context": "and it's pretty impressive how much higher quality"
        },
        {
          "content": "and then if we look at it again with the person on the right it actually looks like somebody doing gymnastics it figured out the proper physics and how people should move here's another one of somebody doing like a weird ring thing where that doesn't look right but if we go back and look at the updated version on the right you can see it actually figured out how to make it look and this is just again a new way of training these AI video models so they have a much better understanding of the physics and how they should look you're going to see this in a lot of other video models you'll probably see this in cling and Runway and hellu Ai and Pika and all these other tools because with this research they can actually sort of attach this to their existing technology now I'm not going to go too deep into these research papers cuz I actually did a video earlier this week called seven insane AI video breakthroughs you must see I talk about those two papers that I just showed you as well as five other papers that I find really fascinating that have come out within the last couple weeks",
          "context": "and then there's also this one called video Jam which is like a new way of training video models that make them so much more coherent like we can see gymnastics what it looks like from most videos on the left here"
        }
      ]
    },
    "roles": {
      "user": [
        {
          "content": "but I record these videos on Thursdays and this news came out on Friday of last week it was when open AI released their 03 mini now we did talk about it in last Friday's video because we knew it was going to come out on Friday but now that we actually have access to it I figured let's talk about it real quick this new 03 model outperforms pretty much every other model out there in math except for 01 Pro which is not actually listed on this chart in PhD level science questions the 03 mini High version beats everything else that's out there except for of course 01",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "Pro it's good at coding good at software engineering and it's pretty much the most powerful model on the market other than 01 Pro which is only in the $200 a month tier this new 03 mini however is available in every tier and available in the API as well Pro users will have unlimited access to 03 mini and plus and team users will have triple the rate limits versus 01 mini free users can try 03 mini in chat GPT by selecting the reason button under the message composer so even free chat GPT users are getting access to this newest state-of-the-art model from open AI you can even combine this 03 Mini model with their search model even on free plans open AI said try search plus reasoning together in chat GPT free users can use open aai 03 min with search by selecting the search plus reason buttons together",
          "matched_patterns": [
            "select",
            "open"
          ]
        },
        {
          "content": "so if you're on the free plan and you want to use the new 03 model you'd select the reason button if you want to combine it with search you select both search and reason",
          "matched_patterns": [
            "select"
          ]
        },
        {
          "content": "open AI said updated Chain of Thought in open aai 03 mini for free and paid users and in 03 mini High for paid users now the Chain of Thought that it's showing here isn't actually the true Chain of Thought that's happening it's not like what you see in deep seek R1 where you see literally everything the model's thinking before it gives you the response this gives you sort of like a summarized version of what it's thinking before it gives you a response McKay Wrigley here even argues that it's actually worse than giving us nothing at all he says 03 mini is exceptionally great",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "but I do worry that summarized Chain of Thought is actually worse than nothing at all true Chain of Thought exposure acts as a prompt debugger it helps us steer the model summarized Chain of Thought up escapes this and potentially adds errors and it makes it harder to debug so if you're looking at something like deep seek R1 and you can see literally everything it's thinking and it gives you an incorrect answer you could literally go back and look through the chain of thought and figure out where it's screwed up these summarized chains of thought that open ai3 is giving us you can't really do that",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "but in my opinion the even bigger news that came out from open AI this week wasn't even the fact that they gave us 03 mini on Friday it was that over the weekend they gave us deep research unfortunately deep research is only available to Pro users on the $200 a month plan which I do know makes it economically infeasible for a lot of people",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "I've just personally found a lot of value from it there's a recent benchmark test that came out titled Humanity's last exam and you can see how some of the other existing models performed on this benchmark test GPT 40 got a 3.3% in accuracy open eyes 01 got a 9.1 deep seek R1 got a 9.4 the new openai 03 mini High got a 13.0 open AI with deep research got a 26 .6% on the accuracy if you have a pro account if you combind 01 Pro with deep research it is hands down the most powerful AI large language model",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "yes only a single digit meaning you know between 1 and 9% but that single digigit percentage still likely adds up to billions of dollars worth of value that this deep research is capable of doing and not only that but Sam te's that there's still something else coming he said note this is not the one more thing for 03 mini a few more days for that and he said that on the same day that deep research came out he was commenting that 03 mini came out and then oh here's deep research which makes all of this stuff even better and we still have one more thing to show you which is exciting but we're not telling you yet but open AI wasn't even done there with announcements this week they had a handful of smaller announcements like the fact that chat GPT search is now a available to everyone over on chat gp.com no sign up required",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "so if you don't want to use Google search anymore you'd rather use chat GPT for your search you can just go to chat gp.com and do web searches that are combined with AI now without even logging in so now it's like an actual true competitor to what perplexity is doing they also increase the memory limit in chat GPT for plus pro and team users by 25%",
          "matched_patterns": [
            "go to"
          ]
        },
        {
          "content": "yeah it's been a big week for open Ai and since open AI had so much going on this week they actually took to Reddit to do an AMA where Sam Alman Mark Chen Kevin wheel serenos nanian Michelle Pocas and hungu ren",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
          "matched_patterns": [
            "enter",
            "input"
          ]
        },
        {
          "content": "so Gemini holds three out of the top five spots right now and the new model from open AI 03 mini Falls all the way down here at 1 2 3 4 5 6 7 8 9 10 the other place I like to look at models is this site open router which I actually learned about from Logan Kilpatrick when he was on our podcast the other day and this is actually looking at Which models are actually getting the most use",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "so this isn't based on voting this is just based on what is actually getting used right now it's somehow watching the apis and going okay these models are what most people are using and on the day of this recording which is Thursday February 6th Claude Sonet holds the top two spots for the all category section but then Google's Gemini models hold the third and fourth spots so when it comes to usage right now Claude and Gemini are being used more than open AI apis at least today if we look at Top This Week very similar story CLA Claude Gemini Gemini followed by open AI top this month Claude Claude Gemini Gemini",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "and then if we look at trending to see which thing people are switching over to and starting to use more and more of recently look at this number one right here Gemini flash 2.0 this is the most trending model right now and this is all categories if we look at programming we've got CLA Claud flash if we look at technology we've got Claud followed by Flash and if we look at translation Gemini Flash the previous generation of model is number one kind of a cool resource to keep tabs on which AI models are actually getting the most use at the moment but Google had some other news this week for developers that use their API you can now use the Imagine 3 AI image generator from their API and we've looked at imagine 3 quite a bit in previous videos it is a really really solid model in fact if we jump back over to the arena here click on our leaderboard if we check out their text image leaderboard we can actually see that imagine three the model from Google is ranked the top model and these are ranked in the same way you're given two images for a prompt you pick which one you like best it doesn't tell you which model you picked until after you picked it and that's how this stuff gets ranked and imagine three is number one followed by recraft followed by idiogram and so on down the line with stable diffusion falling in last",
          "matched_patterns": [
            "click"
          ]
        },
        {
          "content": "google.com over on the right you have the option to select from various models to use and this is totally free right now you've got Gemini 2.0 flash flashlight Pro experimental flash thinking plus all of their previous models and their open source models all available for you to play with and enter prompts here and we can see we've got over a million context window as well all totally free to use over at aist studio.",
          "matched_patterns": [
            "select",
            "open",
            "enter"
          ]
        },
        {
          "content": "and it seems like Demis has sort of changed his thinking on it all right so open a",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "so now I'm going to sort of Rapid Fire a whole bunch of other little things that happen in the world of AI starting with the fact that Mr all AI a sort of competitor to open AI out of France launched a new version of lechette now they've had lechette for a while it's a free chatbot that you can find over at chat.",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "so it's available for free just to give it my own test I'm going to make sure I have the canvas turned on and I'm going to just type generate a kawaii calculator and we'll see how fast this is I'm not going to speed this up at all this is my own test here and when I press the button I will keep on talking it it wrote All That code practically instantly and that was super fast now it created in HTML",
          "matched_patterns": [
            "type"
          ]
        },
        {
          "content": "so SAS is software as a service and if we look at this chart here we can see this is cursor's growth curve it basically took one year to get to 100 million in annual recurring Revenue we can wise deal together AI Core weave open Ai and DocuSign and all of their respective charts it took docine 10 years to get to 100 million in annual recurring Revenue it took cursor only one year that's pretty mind-blowing how quickly cursor is growing",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "and now I have a simple workflow where whenever I grab an image from any app or download on the Internet or anything I don't have to open it up in like a photos app",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "and save it as a new file I literally just drag and drop it over a box it converts it for me automatically it saves me so much time",
          "matched_patterns": [
            "save"
          ]
        },
        {
          "content": "so I see why it's growing so quickly it totally democratized the ability to make simple apps all right let's move on to the sort of creative side of AI cuz there's been a handful of updates in that world as well including the fact that if you use grock inside of X you can now actually edit images if I head over to grock inside of X here and tell it to generate an image of a wolf howling at the moon we get four Images here now if I click on one of these images there's a new button that says edit with Gro I can click on this button and Des describe what I want to change in the image I'll say make the sky a red color we'll give it that prompt",
          "matched_patterns": [
            "click"
          ]
        },
        {
          "content": "but now the sky is a reddish color P Labs rolled out a couple new features this week including the Pika scenes which allows you to upload an image of your pet and it will actually turn that image into an AI generated video of your pet doing something interesting they also rolled out this new feature called Peak editions this is where you can give a real life video plus an image and it will take what was in that image and add it to your video like this rabbit we see here or this person opening their laundry where an octopus climbs out here's a a video of a woman with curlers in her hair and then a lion pushes her aside with curlers in his hair so you can see here's people playing basketball here's an image of a bear it puts the Bear in with them somebody opening a door somebody doing yoga with a train behind them so you can basically give it like any video plus an image and it will figure out how to like work that image into the video It's called Peak editions and this little baby popping out of the trash can is probably my favorite scene I've seen from it",
          "matched_patterns": [
            "open"
          ]
        },
        {
          "content": "and then if we look at it again with the person on the right it actually looks like somebody doing gymnastics it figured out the proper physics and how people should move here's another one of somebody doing like a weird ring thing where that doesn't look right but if we go back and look at the updated version on the right you can see it actually figured out how to make it look and this is just again a new way of training these AI video models so they have a much better understanding of the physics and how they should look you're going to see this in a lot of other video models you'll probably see this in cling and Runway and hellu Ai and Pika and all these other tools because with this research they can actually sort of attach this to their existing technology now I'm not going to go too deep into these research papers cuz I actually did a video earlier this week called seven insane AI video breakthroughs you must see I talk about those two papers that I just showed you as well as five other papers that I find really fascinating that have come out within the last couple weeks",
          "matched_patterns": [
            "go to"
          ]
        },
        {
          "content": "so check that out if you want to dive deeper into all of this cool AI research that's coming out that maybe we don't have access to but it's like within weeks maybe months away of it being publicly available for anybody to get their hands on and a couple last real quick things there's a new bill introduced I believe in the Senate that wants to make it illegal to download deep seek with a penalty of up to 20 years in prison now I don't think this thing's everever going to get passed but there are people in the government that want to make it illegal to use some of these open source models it's something to be aware of and in the final bit of news that I'll share this week the Beatles won a Grammy this week for a song that was assisted with AI",
          "matched_patterns": [
            "open"
          ]
        }
      ],
      "developer": [
        {
          "content": "Pro it's good at coding good at software engineering and it's pretty much the most powerful model on the market other than 01 Pro which is only in the $200 a month tier this new 03 mini however is available in every tier and available in the API as well Pro users will have unlimited access to 03 mini and plus and team users will have triple the rate limits versus 01 mini free users can try 03 mini in chat GPT by selecting the reason button under the message composer so even free chat GPT users are getting access to this newest state-of-the-art model from open AI you can even combine this 03 Mini model with their search model even on free plans open AI said try search plus reasoning together in chat GPT free users can use open aai 03 min with search by selecting the search plus reason buttons together",
          "matched_patterns": [
            "api"
          ]
        },
        {
          "content": "they mentioned there's some updates coming to Advanced voice mode and that they're not calling the next Model 5 it'll just be GPT 5 they talked about how they are planning on increasing context length they're working on the ability to attach files to the reasoning models like 01 and 03 but the comment that's probably gotten the most press that most people have been talking about was when Sam Alman said I personally think we've been on the wrong side of History here and need to figure out a different open-source strategy this was in response to somebody asking would you consider releasing some model weights and Publishing some research he goes on to say not everyone at open AI shares this View and it's also not our current highest priority essentially Sam mman believes that they've been on the wrong side of history with open source and that maybe they should have been open sourcing more of this stuff along the way instead of keeping it all closed off but besides open AI Google had a huge week as well releasing a bunch of new models including Gemini 2.0 the new Gemini 2.0 models look pretty strong in all of the benchmarks although these are just comparing them to previous Gemini models and not with the whole range of AI models that are available and with this release they released actually three new models Gemini 2.0 flash which is now generally available Gemini 2.0 flashlight which is a more efficient version of Gemini 2.0 Flash and Gemini 2.0 pro which is their best state-of-the-art model that they're making available right now they also have their Gemini 2.0 flash thinking model which does some of that extra thinking at the time of inference like we're seeing from things like 01 and 03 and deep seek the two Gemini flash models both have a 1 million token context window while the pro has a 2 million context window and pretty soon 2.0 Flash and pro are going to be able to Output audio and images we recently had Logan killpatrick from Google on the next wve podcast his episode comes out next week and he goes into some details about what's actually coming with these Gemini models and it's pretty exciting but the biggest sort of deal around these new Gemini models is not necessarily how powerful they are it's how inexpensive they are to use if you're a developer and you want to develop with the Gemini apis Gemini 2.0 flash cost 10 cents per million tokens to put that into context if you're using the GPT 40 API it cost $10 per million tokens that's quite a bit of savings there their 01 model $60 per million tokens if you're looking at Claude 3.5 Sonet $15 per million tokens and even hu their smallest model is still $4 per million tokens and so far I've just been looking at the outputs",
          "matched_patterns": [
            "api"
          ]
        },
        {
          "content": "so if you're a developer and you want to build with a large language model API and you want to do it as inexpensively as possible Gemini 2.0 is definitely your route right now now when it comes to actually comparing these models against other models there's really two places to look especially if you're confused by all the benchmarks that they share first is the LM Arena where basically people are given a blind test they enter a prompt they get two outputs they pick which of the two outputs they like better and that's how this ranking is generated and if we look at this based on the blind testing Gemini's 2.0 flash thinking model is the number one ranked overall model right now just based on users giving it an input not knowing that they're getting Gemini back and then voting Gemini as the best response Gemini 2.0 pro the new one that came out on February 5th came in second place followed by GPT 40 deep seek R1 and then Gemini 2.0 flash",
          "matched_patterns": [
            "api"
          ]
        },
        {
          "content": "so this isn't based on voting this is just based on what is actually getting used right now it's somehow watching the apis and going okay these models are what most people are using and on the day of this recording which is Thursday February 6th Claude Sonet holds the top two spots for the all category section but then Google's Gemini models hold the third and fourth spots so when it comes to usage right now Claude and Gemini are being used more than open AI apis at least today if we look at Top This Week very similar story CLA Claude Gemini Gemini followed by open AI top this month Claude Claude Gemini Gemini",
          "matched_patterns": [
            "api"
          ]
        },
        {
          "content": "and then if we look at trending to see which thing people are switching over to and starting to use more and more of recently look at this number one right here Gemini flash 2.0 this is the most trending model right now and this is all categories if we look at programming we've got CLA Claud flash if we look at technology we've got Claud followed by Flash and if we look at translation Gemini Flash the previous generation of model is number one kind of a cool resource to keep tabs on which AI models are actually getting the most use at the moment but Google had some other news this week for developers that use their API you can now use the Imagine 3 AI image generator from their API and we've looked at imagine 3 quite a bit in previous videos it is a really really solid model in fact if we jump back over to the arena here click on our leaderboard if we check out their text image leaderboard we can actually see that imagine three the model from Google is ranked the top model and these are ranked in the same way you're given two images for a prompt you pick which one you like best it doesn't tell you which model you picked until after you picked it and that's how this stuff gets ranked and imagine three is number one followed by recraft followed by idiogram and so on down the line with stable diffusion falling in last",
          "matched_patterns": [
            "api"
          ]
        },
        {
          "content": "so now I'm going to sort of Rapid Fire a whole bunch of other little things that happen in the world of AI starting with the fact that Mr all AI a sort of competitor to open AI out of France launched a new version of lechette now they've had lechette for a while it's a free chatbot that you can find over at chat.",
          "matched_patterns": [
            "api"
          ]
        },
        {
          "content": "m.ai and it can do a lot of the same things you would get out of chat GPT things like search the web generate images code interpreter and it even has a canvas mode where it'll put any sort of code and writing inside of a canvas very similar to chat GPT they do now have a Pro Plan which I believe is 15 bucks a month",
          "matched_patterns": [
            "code"
          ]
        },
        {
          "content": "so they do have a Pro Plan now available that gives even more access and reduces the limit of messages per day but even the free version is still pretty dang impressive the most impressive part about mraw is how fast it is people have been claiming they're getting a th000 tokens per second output when they ask it a question which is mind-blowingly fast in fact I came across this video from Val on X here who is an intern over at mraw and well just check this out they give it the prompt generate me a kawaii calculator in canvas and we can see that it actually generated everything in like near real time that calculator that popped up that happened in real time I didn't speed up this video they didn't speed up their video they gave it the prompt to generate the kauwaii calculator and it generated the code showed an example of it they started giving it some extra prompts like now make it nature themed and within seconds created a nature themed calculator and it's all like practically instant that's how fast it is and we can see Val here says no this video is not sped up genuinely mind-blowing and it's available to all users right now",
          "matched_patterns": [
            "code"
          ]
        },
        {
          "content": "so it's available for free just to give it my own test I'm going to make sure I have the canvas turned on and I'm going to just type generate a kawaii calculator and we'll see how fast this is I'm not going to speed this up at all this is my own test here and when I press the button I will keep on talking it it wrote All That code practically instantly and that was super fast now it created in HTML",
          "matched_patterns": [
            "code"
          ]
        },
        {
          "content": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat",
          "matched_patterns": [
            "code"
          ]
        },
        {
          "content": "and I don't really know how to code",
          "matched_patterns": [
            "code"
          ]
        },
        {
          "content": "so I made it super super easy to filter them and find the exact tool you're looking for for your needs even put a match pick on here so you can find the tools that I think are the most interesting right now I keep the AI news page up to date on a daily basis I keep it simple and basic and just a list of here's all the important AI news that's happening and if you want to get the latest news and the coolest tools mailed to you twice a week join the free newsletter I'll keep you looped in directly in your inbox and by joining the free newsletter you also get access to the AI income database which is a little database I've been building out of cool ways to make money using the various AI tools that are available again it's all free over at futur tools.",
          "matched_patterns": [
            "import"
          ]
        }
      ],
      "config": [
        {
          "content": "it's like watching somebody use Internet Explorer but in 2025 painfully unnecessary and that's why for this video I partnered with chat base they're revolutionizing the customer experience with AI agents that don't just chat they actually do things for you we're talking AI that can instantly book meetings through calendly create support tickets with zenes or even check realtime data from your own systems what makes this really cool is that these AI agents can be trained on your own business data they're not just giving generic responses they're providing personalized help that actually makes sense it can do things on behalf of your business for your customers things like upgrading their subscription for them adding members to a dashboard for you and checking the limits of their plan all based on your custom workflows plus they work across all your channels from your website to WhatsApp to slack so that your customers can get help wherever they are and the best part you don't need to be a coding wizard to set this up chatbase has made it super simple to set up and manage these AI agents no matter what your technical level is anybody can set these things up if you want to see how chatbase can transform your customer experience from please wait to it's done check out the link in the description trust me your customers are going to thank you for this one and thank you so much to chat base for sponsoring this video there is a little bit of Darker news to come out of Google this week",
          "matched_patterns": [
            "set up"
          ]
        }
      ],
      "troubleshoot": [
        {
          "content": "open AI said updated Chain of Thought in open aai 03 mini for free and paid users and in 03 mini High for paid users now the Chain of Thought that it's showing here isn't actually the true Chain of Thought that's happening it's not like what you see in deep seek R1 where you see literally everything the model's thinking before it gives you the response this gives you sort of like a summarized version of what it's thinking before it gives you a response McKay Wrigley here even argues that it's actually worse than giving us nothing at all he says 03 mini is exceptionally great",
          "matched_patterns": [
            "exception"
          ]
        },
        {
          "content": "but I do worry that summarized Chain of Thought is actually worse than nothing at all true Chain of Thought exposure acts as a prompt debugger it helps us steer the model summarized Chain of Thought up escapes this and potentially adds errors and it makes it harder to debug so if you're looking at something like deep seek R1 and you can see literally everything it's thinking and it gives you an incorrect answer you could literally go back and look through the chain of thought and figure out where it's screwed up these summarized chains of thought that open ai3 is giving us you can't really do that",
          "matched_patterns": [
            "error",
            "debug"
          ]
        },
        {
          "content": "there was a little bit of news out of anthropic this week they gave us an area to try to jailbreak clad and see if we can get it to Output dangerous responses there's eight levels that it goes through and they actually have a bounty where they'll actually pay you if you manage to jailbreak all eight questions so far nobody's managed to do it but there is a little bit of other news around anthropic Lyft is starting to use anthropic clad for their customer service claiming that it reduces the average resolution time for a request by 87%",
          "matched_patterns": [
            "solution"
          ]
        },
        {
          "content": "so if you're using Lyft and you run into issues",
          "matched_patterns": [
            "issue"
          ]
        },
        {
          "content": "and you try to contact customer support it's actually using Claud to sort of help you get through whatever issue you've got we also learned that Amazon Alexa has an event coming up on February 26 Amazon's holding an event and a spokesperson said the event is Alexa focused but then declined to elaborate",
          "matched_patterns": [
            "issue"
          ]
        },
        {
          "content": "so that's the announcement that everybody's expecting on February 26th is that Alexa is now going to use Claude and it's not going to be as dumb as it used to be GitHub co-pilot now has what they call agent mode it says here that the new agent mode is capable of iterating on its own code recognizing errors and fixing them automatically it can suggest terminal commands and ask you to execute them it also analyzes runtime errors with selfhealing capabilities so it sounds to me like it's using one of these like reasoning models where it will generate code sort of double check its own code and then give you the code it says in agent mode co-pilot will iterate on not just its own output but the results of that output it will iterate in until it has completed all subtasks required to complete your prompt instead of Performing just the task you requested co-pilot now has the ability to infer additional tasks that were not specified but are also necessary for the primary request to work even better it can catch its own errors Fring you up from having to copy paste from the terminal back into chat",
          "matched_patterns": [
            "error",
            "fix",
            "catch"
          ]
        },
        {
          "content": "and I think it comes down to the fact that tools like cursor make it so literally anybody on the planet can write little software for themselves I've used it multiple times to solve little problems in my own workflows like I wanted a tool to quickly convert files from any image format into a JPEG I use cursor to create that app in about 15 minutes",
          "matched_patterns": [
            "problem"
          ]
        },
        {
          "content": "but that's Peak Edition something fun to go play around with but I also wanted to show off what came out of topaz labs this week a company that makes a really really good upscaler I use it to upscale images all the time I use it to upscale video footage all the time they actually just released what they call Project Starlight which is the first ever diffusion model for video restoration so it takes old lowquality videos and turns them into high resolution videos so let's take a peek at this video down here of a Muhammad Ali fight you can see on the left how sort of grainy and pixely it is and the one on the right is the more upscaled version that use this project Starlite",
          "matched_patterns": [
            "solution"
          ]
        }
      ]
    },
    "stats": {
      "total_length": 35001,
      "pattern_matches": 20,
      "semantic_matches": 62,
      "role_matches": 47
    }
  }
}